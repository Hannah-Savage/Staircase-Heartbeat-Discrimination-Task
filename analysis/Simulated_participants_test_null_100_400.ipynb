{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d717e633-cde0-4953-b8de-fff7cbb4a26f",
   "metadata": {},
   "source": [
    "# Set env:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f601df1-0259-4164-aead-f0683858253f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.stats import norm, linregress\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from IPython.display import display, HTML\n",
    "from tqdm import tqdm \n",
    "pd.set_option('display.width', 1000)\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4c40c1-971d-4f26-9d79-739c82996a52",
   "metadata": {},
   "source": [
    "# Define functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df06e18-e740-4a6a-8979-cf840a2370bd",
   "metadata": {},
   "source": [
    "REFERENCE SAMPLE: Function to create simuation_matrix. Creates plots of Point of subjective simultaneity (PSS) and accuracy trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39e8030-e2b8-4ef5-9ace-615d5af1e563",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reference_matrix(simulation_df, pred_pss_values, pred_accuracies, drop = True, plots = False):\n",
    "    \n",
    "    # Recode trial numbers: Make trials continuous from 1-30\n",
    "    simulation_df['Recode_Trial'] = np.where(simulation_df['Staircase_name'].str.contains('400'),\n",
    "                                             simulation_df['Trial'], \n",
    "                                             simulation_df['Trial'] + 15)\n",
    "    \n",
    "    \n",
    "    if plots:   \n",
    "        colors = plt.cm.viridis(np.linspace(0, 1, len(pred_accuracies)))  # Color map for accuracy levels\n",
    "\n",
    "        # Create a grid for the subplots\n",
    "        n_rows = 4\n",
    "        n_cols = 2\n",
    "        n_iterations = 100\n",
    "        fig, axs = plt.subplots(n_rows, n_cols, figsize=(12,12), dpi=300)\n",
    "        axs = axs.ravel()  # Flatten the 2D array of axes to 1D for easy iteration\n",
    "        plt.rcParams.update({'font.size': 8})\n",
    "        for i, pss_value in enumerate(pred_pss_values):\n",
    "            ax = axs[i]\n",
    "            df_pss = simulation_df[simulation_df['PSS_value'] == pss_value]\n",
    "\n",
    "            # Set title for the subplot\n",
    "            ax.set_title(f'{pss_value} ms', fontsize=16,  loc='left')\n",
    "\n",
    "            # Loop through each accuracy value\n",
    "            for accuracy_idx, accuracy in enumerate(pred_accuracies):\n",
    "                # Filter data by accuracy and group by Staircase_name and Trial\n",
    "                df_accuracy = df_pss[df_pss['Accuracy'] == accuracy]\n",
    "                mean_stim_values = df_accuracy.groupby(['Staircase_name', 'Trial'])['Current Delay'].mean()\n",
    "                std_stim_values = df_accuracy.groupby(['Staircase_name', 'Trial'])['Current Delay'].std()\n",
    "\n",
    "                # Plot each staircase separately\n",
    "                for staircase_name, group in mean_stim_values.groupby(level=0):\n",
    "                    # Compute 95% confidence intervals\n",
    "                    trial_numbers = group.index.get_level_values(1)\n",
    "                    #ci_95 = 1.96 * std_stim_values.loc[staircase_name] / np.sqrt(n_iterations)\n",
    "\n",
    "\n",
    "                    x_vals = group.index.get_level_values(1).to_numpy()\n",
    "                    y_vals = group.values.astype(float).flatten()  # Ensure 1D\n",
    "                    ci_vals = std_stim_values.loc[staircase_name].values.astype(float).flatten() * 1.96 / np.sqrt(n_iterations)\n",
    "                    ax.plot(x_vals, y_vals, \n",
    "                            label=f'{staircase_name} - Accuracy {accuracy*100:.0f}%', \n",
    "                            color=colors[accuracy_idx], \n",
    "                            marker='o')\n",
    "\n",
    "                    ax.fill_between(x_vals, \n",
    "                                    y_vals - ci_vals, \n",
    "                                    y_vals + ci_vals, \n",
    "                                    color=colors[accuracy_idx], \n",
    "                                    alpha=0.2)\n",
    "\n",
    "                    # Plot the mean stimulus values and confidence intervals\n",
    "                    #ax.plot(group.index.get_level_values(1), group.values, \n",
    "                    #        label=f'{staircase_name} - Accuracy {accuracy*100:.0f}%', \n",
    "                    #        color=colors[accuracy_idx], \n",
    "                    #        marker='o')\n",
    "\n",
    "                    #ax.fill_between(group.index.get_level_values(1), \n",
    "                    #                group.values - ci_95, \n",
    "                    #                group.values + ci_95, \n",
    "                    #                color=colors[accuracy_idx], \n",
    "                    #                alpha=0.2)\n",
    "\n",
    "            # Labeling the subplot\n",
    "            ax.set_xlabel('Trial')\n",
    "            ax.set_ylabel('Delay (ms)')\n",
    "            ax.set_ylim(0, 800)  # Set y-axis limit between 0 and 800\n",
    "            #ax.legend(loc='upper right')\n",
    "            ax.axhspan((pss_value-1), (pss_value +1), color='red', alpha=1.0, linestyle = '--', zorder=10)\n",
    "\n",
    "            # Adjust layout for better spacing between subplots\n",
    "            plt.tight_layout()\n",
    "\n",
    "            \n",
    "            save_path = '/PATH/Reference_trajectories_100_400.png'\n",
    "            \n",
    "        plt.savefig(save_path) \n",
    "        plt.show()\n",
    "        print(f\"Saved to {save_path}\")\n",
    "    \n",
    "    if drop: \n",
    "        #Remove the first two trials from each staircase\n",
    "        #simulation_df = simulation_df[~simulation_df['Recode_Trial'].isin([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25])] #last 5 trials only\n",
    "        simulation_df = simulation_df[~simulation_df['Recode_Trial'].isin([1, 2, 3, 4, 5, 16, 17, 18, 19, 20])] #trials 5-15\n",
    "\n",
    "    \n",
    "    # Create a pivot table to calculate mean delay\n",
    "    pivot_df = simulation_df.pivot_table(\n",
    "        index=['PSS_value', 'Recode_Trial'],  # Depth: PSS_value; Rows: Trial number\n",
    "        columns='Accuracy',                  # Columns: Accuracy values\n",
    "        values='Current Delay',              # Values: Mean Delay\n",
    "        aggfunc='mean'                       # Aggregate function: mean\n",
    "    )\n",
    "    \n",
    "    # Only use PSS = 100-400; exclude PSS isin([50, 450, 500, 550, 600]\n",
    "    pivot_df = pivot_df.loc[~pivot_df.index.get_level_values('PSS_value').isin([50, 450, 500, 550, 600])]\n",
    "    \n",
    "    # Fill missing values\n",
    "    pivot_df = pivot_df.fillna(0)\n",
    "    \n",
    "    # Prepare labels for heatmaps\n",
    "    trial_labels = [f\"Trial {i}\" for i in sorted(simulation_df['Recode_Trial'].unique())]\n",
    "    accuracy_labels = [f\"Acc {round(acc, 2)}\" for acc in sorted(simulation_df['Accuracy'].unique())]\n",
    "    pss_values = sorted(pivot_df.index.get_level_values('PSS_value').unique())\n",
    "    #pss_values = sorted(simulation_df[~simulation_df['PSS_value'].isin([50, 450, 500, 550, 600])\n",
    "\n",
    "    return pivot_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b8ba6b",
   "metadata": {},
   "source": [
    "REFERENCE SAMPLE: Function to compute response counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733217c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_response_counts(participants_df, participant_id, i):\n",
    "    # Count the occurrences of each response code per Staircase_name\n",
    "    response_counts = participants_df.groupby(['Staircase_name', 'Response_code']).size().unstack(fill_value=0)\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    response_counts = response_counts.rename(columns={-1: \"Before_Response\", \n",
    "                                                       0: \"Same_Response\", \n",
    "                                                       1: \"After_Response\"})\n",
    "    \n",
    "    # Reset index for merging or visualization\n",
    "    response_counts = response_counts.reset_index()\n",
    "    \n",
    "    # Add participant_id column\n",
    "    response_counts['participant_id'] = f\"{participant_id}_{i}\"\n",
    "    \n",
    "    return response_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e59c79",
   "metadata": {},
   "source": [
    "REFERENCE SAMPLE: Function to calculate how many participants had >5 or <15 button presses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd594ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_participants_outside_range_melted(df, staircase_name):\n",
    "    \"\"\"\n",
    "    Returns a set of participant IDs whose any Count value for the given staircase_name is outside [5, 15]\n",
    "    \"\"\"\n",
    "    filtered = df[df['Modified_Staircase_name'] == staircase_name]\n",
    "    \n",
    "    # Find rows where Count is outside the range [5, 15]\n",
    "    outside_range = filtered[(filtered['Count'] < 5) | (filtered['Count'] > 15)]\n",
    "    \n",
    "    # Return unique participant_ids\n",
    "    return set(outside_range['participant_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cc59af-6a68-4f94-b022-172bdc8a36ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "REFERENCE SAMPLE: Function to get end trial difference values for reference sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5faee40-1a1b-42d8-a2df-0b4f8a4e638f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reference_diff_beg_end(simulation_df, pss_value_list, accuracy_list, plots=True):\n",
    "    \n",
    "    diff_df = pd.DataFrame()\n",
    "\n",
    "    # Initialize figure if plotting is enabled\n",
    "    #if plots:\n",
    "    #    fig, axes = plt.subplots(nrows=11, ncols=12, figsize=(22, 18), sharex=False, sharey=False)\n",
    "    #    fig.suptitle(\"Staircase 100 vs. 400 (All Available Trials) Across PSS & Accuracy\", fontsize=16)\n",
    "\n",
    "\n",
    "    for i, pss_value in enumerate(pss_value_list):\n",
    "        df_pss = simulation_df[simulation_df['PSS_value'] == pss_value]\n",
    "\n",
    "        for j, accuracy in enumerate(accuracy_list):\n",
    "            df_accuracy = df_pss[df_pss['Accuracy'] == accuracy]\n",
    "\n",
    "            if df_accuracy.empty:\n",
    "                continue  # Skip if no data\n",
    "\n",
    "            # Compute mean 'Current Delay' per staircase and trial\n",
    "            mean_stim_values = df_accuracy.groupby(['Staircase_name', 'Trial'])['Current Delay'].mean()\n",
    "            #mean_stim_values = mean_stim_values[mean_stim_values.index.get_level_values('Trial').isin(range(6, 16))]\n",
    "\n",
    "            # If you want to check the output after filtering\n",
    "            #print(mean_stim_values)\n",
    "            # Reshape into a DataFrame for easier handling\n",
    "            mean_stim_values = mean_stim_values.unstack(level=0)  # Columns = staircase names\n",
    "            \n",
    "            # Ensure both staircases (400 & 100) are present\n",
    "            if '400' in mean_stim_values.columns and '100' in mean_stim_values.columns:\n",
    "                staircase_400 = mean_stim_values['400'].dropna()\n",
    "                staircase_100 = mean_stim_values['100'].dropna()\n",
    "                \n",
    "            start_400 = mean_stim_values['400'][1]\n",
    "            end_400 = mean_stim_values['400'][15]\n",
    "            #print(f\"{pss_value} - {accuracy}: 400: {start_400}, {end_400}\")\n",
    "\n",
    "            start_100 = mean_stim_values['100'][1]\n",
    "            end_100 = mean_stim_values['100'][15]\n",
    "            #print(f\"{pss_value} - {accuracy}: 100: {start_100}, {end_100}\")\n",
    "\n",
    "            start_diff = start_400 - start_100\n",
    "            end_diff = end_400 - end_100\n",
    "            \n",
    "            #print(f\"{start_diff}, {end_diff}\")\n",
    "            \n",
    "            \n",
    "                       # Create a new row as a DataFrame\n",
    "            new_row = pd.DataFrame({\n",
    "                'PSS_Value': [pss_value],\n",
    "                'Accuracy': [accuracy],\n",
    "                'start_400': [start_400],\n",
    "                'end_400': [end_400],\n",
    "                'start_100': [start_100],\n",
    "                'end_100': [end_100],\n",
    "                'start_diff': [start_diff],\n",
    "                'end_diff': [end_diff]\n",
    "            })\n",
    "            \n",
    "            # Concatenate the new row with the existing DataFrame\n",
    "            diff_df = pd.concat([diff_df, new_row], ignore_index=True)\n",
    "\n",
    "            \n",
    "    return diff_df\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb31dad",
   "metadata": {},
   "source": [
    "SIMULATED SAMPLE: Function to compute response counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a54477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_response_counts_simulated_participants(participants_df, participant_id):\n",
    "    \n",
    "    #print(f\"Processing participant_id: {participant_id}, num rows: {len(participants_df)}\")\n",
    "    \n",
    "    # Count the occurrences of each response code per Staircase_name\n",
    "    response_counts = participants_df.groupby(['Staircase_name', 'Response_code']).size().unstack(fill_value=0)\n",
    "    \n",
    "    # Rename columns for \n",
    "    response_counts = response_counts.rename(columns={-1: \"Before_Response\", \n",
    "                                                       0: \"Same_Response\", \n",
    "                                                       1: \"After_Response\"})\n",
    "    \n",
    "    # Reset index for merging or visualization\n",
    "    response_counts = response_counts.reset_index()\n",
    "    \n",
    "    # Add participant_id column\n",
    "    response_counts['participant_id'] = participant_id\n",
    "    \n",
    "    return response_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a633f653",
   "metadata": {},
   "source": [
    "SIMUATED SAMPLE: Function to calculate how many participants had >5 or <15 button presses per staircase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb658b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_participants_with_values_outside_range_for_staircase_type(pivoted_df, staircase_type='100'):\n",
    "    \"\"\"\n",
    "    This function counts the number of participants whose any of the response columns for the specified staircase type\n",
    "    (e.g., '100' or '400') fall outside the range [5, 15].\n",
    "\n",
    "    Parameters:\n",
    "    pivoted_df : DataFrame\n",
    "        The pivoted DataFrame with response counts.\n",
    "    staircase_type : str\n",
    "        The staircase type ('100' or '400') to filter for.\n",
    "\n",
    "    Returns:\n",
    "    int\n",
    "        The number of participants whose any of the response columns fall outside the range [5, 15].\n",
    "    \"\"\"\n",
    "    # Define the response columns\n",
    "    response_columns = ['Before_Response', 'Same_Response', 'After_Response']\n",
    "    \n",
    "    # Filter the columns based on the staircase type (e.g., '100' or '400')\n",
    "    staircase_columns = [f\"{col}_{staircase_type}\" for col in response_columns]\n",
    "    \n",
    "    # Check if any of the columns for this staircase type fall outside the range [5, 15]\n",
    "    condition = (pivoted_df[staircase_columns] <= 5) | (pivoted_df[staircase_columns] >= 15)\n",
    "    \n",
    "    # Get the participant IDs where any of the conditions hold true (i.e., any value falls outside [5, 15])\n",
    "    participants_outside_range = pivoted_df[condition.any(axis=1)].index.tolist()\n",
    "    \n",
    "    return participants_outside_range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aa03b3",
   "metadata": {},
   "source": [
    "SIMUATED SAMPLE: Function to calculate how many participants had >5 or <15 button presses in either staircase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5441fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_overall_outside_range(pivoted_df):\n",
    "    \"\"\"\n",
    "    This function counts the number of unique participants whose any response column for either staircase type\n",
    "    ('100' or '400') falls outside the range [5, 15].\n",
    "\n",
    "    Parameters:\n",
    "    pivoted_df : DataFrame\n",
    "        The pivoted DataFrame with response counts.\n",
    "    \n",
    "    Returns:\n",
    "    unique_participants_outside_range : list\n",
    "        The list of unique participant IDs who meet the condition for either staircase type.\n",
    "    \"\"\"\n",
    "    # Get participants for staircase '100'\n",
    "    participants_100_outside_range = count_participants_with_values_outside_range_for_staircase_type(pivoted_df, staircase_type='100')\n",
    "\n",
    "    # Get participants for staircase '400'\n",
    "    participants_400_outside_range = count_participants_with_values_outside_range_for_staircase_type(pivoted_df, staircase_type='400')\n",
    "\n",
    "    # Combine the two lists to get unique participants (those who meet either or both conditions)\n",
    "    unique_participants_outside_range = list(set(participants_100_outside_range) | set(participants_400_outside_range))\n",
    "    \n",
    "    return unique_participants_outside_range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a201dde-be33-44c8-9ed7-4e1632d29637",
   "metadata": {},
   "source": [
    "SIMULATED SAMPLE: Function to process and plot data for each PSS value, grouped by Staircase_name and Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dbd7d7-a508-4eda-8f74-53f141d5f98a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_simulations_with_participant_data(simulation_df, participant_df, participant_id, pss_value_list, accuracy_list, n_iterations, trials_per_iteration=15):\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(accuracy_list)))  # Color map for accuracy levels\n",
    "    participant_df = participant_df[participant_df['Participant_ID'] == participant_id]\n",
    "    \n",
    "    # Create a grid for the subplots\n",
    "    n_rows = 3\n",
    "    n_cols = 3\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(18, 12))\n",
    "    axs = axs.ravel()  # Flatten the 2D array of axes to 1D for easy iteration\n",
    "\n",
    "    # Loop through each PSS value\n",
    "    for i, pss_value in enumerate(pss_value_list):\n",
    "        ax = axs[i]\n",
    "        df_pss = simulation_df[simulation_df['PSS_value'] == pss_value]\n",
    "        \n",
    "        # Set title for the subplot\n",
    "        ax.set_title(f'PSS Value: {pss_value} ms', fontsize=14)\n",
    "\n",
    "        # Loop through each accuracy value\n",
    "        for accuracy_idx, accuracy in enumerate(accuracy_list):\n",
    "            # Filter data by accuracy and group by Staircase_name and Trial\n",
    "            df_accuracy = df_pss[df_pss['Accuracy'] == accuracy]\n",
    "            mean_stim_values = df_accuracy.groupby(['Staircase_name', 'Trial'])['Current Delay'].mean()\n",
    "            std_stim_values = df_accuracy.groupby(['Staircase_name', 'Trial'])['Current Delay'].std()\n",
    "\n",
    "            # Plot each staircase separately\n",
    "            for staircase_name, group in mean_stim_values.groupby(level=0):\n",
    "                # Compute 95% confidence intervals\n",
    "                trial_numbers = group.index.get_level_values(1)\n",
    "                ci_95 = 1.96 * std_stim_values.loc[staircase_name] / np.sqrt(n_iterations)\n",
    "\n",
    "                # Plot the mean stimulus values and confidence intervals\n",
    "                ax.plot(group.index.get_level_values(1), group.values, \n",
    "                        label=f'{staircase_name} - Accuracy {accuracy*100:.0f}%', \n",
    "                        color=colors[accuracy_idx], \n",
    "                        marker='o')\n",
    "\n",
    "                ax.fill_between(group.index.get_level_values(1), \n",
    "                                group.values - ci_95, \n",
    "                                group.values + ci_95, \n",
    "                                color=colors[accuracy_idx], \n",
    "                                alpha=0.2)\n",
    "\n",
    "        # Overlay participant data (mean of repeated staircases)\n",
    "        # Group participant data by Modified Staircase_name and Trial\n",
    "        participant_mean_data = participant_df.groupby(['Modified_Staircase_name', 'Trial'])['Current Delay'].mean()\n",
    "        participant_std_data = participant_df.groupby(['Modified_Staircase_name', 'Trial'])['Current Delay'].std()\n",
    "\n",
    "        # Plot each staircase mean with a different line\n",
    "        for staircase_name in participant_df['Modified_Staircase_name'].unique():\n",
    "            # Filter participant data for the current staircase\n",
    "            participant_data_for_staircase = participant_mean_data.loc[staircase_name]\n",
    "            if len(participant_data_for_staircase) > 1:  # Ensure there is more than 1 data point\n",
    "                trial_numbers = participant_data_for_staircase.index  # X-axis: Trial numbers\n",
    "                mean_delays = participant_data_for_staircase.values  # Y-axis: Current Delay values\n",
    "\n",
    "                # Compute confidence intervals for participant datas\n",
    "                ci_participant_95 = 1.96 * participant_std_data.loc[staircase_name] / np.sqrt(n_iterations)\n",
    "\n",
    "                # Plot the participant mean and confidence interval\n",
    "                ax.plot(trial_numbers, mean_delays, \n",
    "                        label=f'Participant ({staircase_name})', \n",
    "                        color='red', \n",
    "                        linewidth=2, \n",
    "                        marker='x')\n",
    "\n",
    "                ax.fill_between(trial_numbers, \n",
    "                                mean_delays - ci_participant_95, \n",
    "                                mean_delays + ci_participant_95, \n",
    "                                color='red', alpha=0.2)\n",
    "\n",
    "        # Labeling the subplot\n",
    "        ax.set_xlabel('Trial')\n",
    "        ax.set_ylabel('Current Delay (ms)')\n",
    "        ax.set_ylim(0, 800)  # Set y-axis limit between 0 and 800\n",
    "        #ax.legend(loc='upper right')\n",
    "\n",
    "    # Adjust layout and show the plot\n",
    "    file_name = '/PATH/Trajectory_plots_simulations/PSS_stimulus_progression_sub-' + participant_id + '.png'\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(file_name)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed06122a-5271-4e5b-af7b-34a4134afdb5",
   "metadata": {
    "tags": []
   },
   "source": [
    "SIMULATED SAMPLE: Function to generate 'participant_matrix'. For each participant returns pred_pss_value, pred_accuracy, rmse, rmse_table, and optional heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9f6d5e-dee4-43ed-9dcb-7660c35a91d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def participant_matrix(df, participant_id, pivot_df, drop = True, plots=False, verbose=False):\n",
    "    # Filter the data for this participant directly from the DataFrame\n",
    "    participant_data = df[df['Participant_ID'] == participant_id]\n",
    "    #print(participant_data)\n",
    "    if participant_data.empty:\n",
    "        # If no data is found, return None\n",
    "        return None, None, None, None, None  # Return None if no data is found\n",
    "\n",
    "    # Recode the trial numbers: 1-15 for 400ms, 16-30 for 100ms\n",
    "    participant_data.loc[:, 'Recode_Trial'] = np.where(participant_data['Staircase_name'].str.contains('400'),\n",
    "                                                       participant_data['Trial'], \n",
    "                                                       participant_data['Trial'] + 15)\n",
    "\n",
    "    # For 400ms (trials 1-15)\n",
    "    mean_delays_400 = participant_data[participant_data['Staircase_name'].str.contains('400')] \\\n",
    "                        .groupby('Recode_Trial')['Current Delay'].mean()\n",
    "\n",
    "    # For 100ms (trials 16-30)\n",
    "    mean_delays_100 = participant_data[participant_data['Staircase_name'].str.contains('100')] \\\n",
    "                        .groupby('Recode_Trial')['Current Delay'].mean()\n",
    "\n",
    "    # Combine the two mean delay series (400_1, 400_2, and 100_1, 100_2) into one DataFrame\n",
    "    #mean_delays = mean_delays_400.append(mean_delays_100)\n",
    "    mean_delays = pd.concat([mean_delays_400, mean_delays_100])\n",
    "\n",
    "    # Reindex the trials: 1-15 for 400ms, 16-30 for 100ms\n",
    "    mean_delays.index = np.arange(1, 31)\n",
    "\n",
    "    if drop:\n",
    "        #mean_delays = mean_delays.drop([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]) # last 5 trials only\n",
    "        mean_delays = mean_delays.drop([1, 2, 3, 4, 5, 16, 17, 18, 19, 20]) #trials 5-15\n",
    "\n",
    "    if verbose: \n",
    "        print('Mean Delays:')\n",
    "        print(mean_delays)\n",
    "        \n",
    "    # Create an empty DataFrame to store the RMSE values for each PSS and accuracy level\n",
    "    rmse_table = pd.DataFrame(index=pivot_df.index.get_level_values('PSS_value').unique(), \n",
    "                              columns=[round(i * 0.1, 1) for i in range(11)])\n",
    "\n",
    "    # Loop through each PSS value and accuracy level, calculate RMSE and store it in the table\n",
    "    for pss in rmse_table.index:\n",
    "        for accuracy in rmse_table.columns:\n",
    "            # Extract the trial indices for the current PSS and accuracy level from pivot_df\n",
    "            trial_indices = pivot_df.xs(pss, level='PSS_value').loc[:, accuracy].index\n",
    "\n",
    "            # Extract corresponding mean delay values for those trials\n",
    "            mean_delay_values = mean_delays.loc[trial_indices].values\n",
    "\n",
    "            # Extract the corresponding pivot values for the current PSS and accuracy level\n",
    "            pivot_values = pivot_df.xs(pss, level='PSS_value').loc[:, accuracy].values\n",
    "\n",
    "            # Calculate RMSE if both arrays are not empty\n",
    "            if mean_delay_values.size > 0 and pivot_values.size > 0:\n",
    "                rmse = np.sqrt(np.mean((mean_delay_values - pivot_values) ** 2))\n",
    "            else:\n",
    "                rmse = np.nan  # If no data is available, assign NaN\n",
    "\n",
    "            # Store the RMSE in the table\n",
    "            rmse_table.loc[pss, accuracy] = rmse\n",
    "    \n",
    "    if verbose: \n",
    "        display(HTML(rmse_table.to_html()))\n",
    "\n",
    "    # Ensure the RMSE table is numeric (in case of any issues with non-numeric values)\n",
    "    rmse_table = rmse_table.apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "        # 2. Find the lowest 5 RMSE values\n",
    "    lowest_rmse = rmse_table.unstack().sort_values().head(5)\n",
    "\n",
    "    # Display the lowest 5 RMSE values along with corresponding PSS and accuracy levels\n",
    "    lowest_rmse_table = pd.DataFrame(lowest_rmse).reset_index()\n",
    "    lowest_rmse_table.columns = ['Accuracy_Level', 'PSS_Value', 'RMSE']\n",
    "    \n",
    "    if verbose: \n",
    "        display(HTML(lowest_rmse_table.to_html()))\n",
    "        print(f\"{lowest_rmse_table[0:1]['PSS_Value']} \\n {lowest_rmse_table[0:1]['Accuracy_Level']} \\n {lowest_rmse_table[0:1]['RMSE']}\")\n",
    "\n",
    "    # Assuming that pred_pss_value, pred_accuracy, and rmse are the first values from lowest_rmse_table\n",
    "    pred_pss_value = lowest_rmse_table['PSS_Value'].values[0]\n",
    "    pred_accuracy = lowest_rmse_table['Accuracy_Level'].values[0]\n",
    "    rmse = lowest_rmse_table['RMSE'].values[0]\n",
    "    \n",
    "    \n",
    "    # Plot if requested\n",
    "    if plots:\n",
    "        rmse_table = rmse_table.iloc[::-1]\n",
    "        # Create the heatmap\n",
    "        plt.figure(figsize=(12, 8))  # Adjust figure size if necessary\n",
    "        sns.heatmap(rmse_table, annot=True, cmap=\"coolwarm\", cbar_kws={'label': 'RMSE'}, fmt='.1f')\n",
    "        plt.title(\"Heatmap of RMSE for Different PSS Values and Accuracy Levels\")\n",
    "        plt.xlabel(\"Accuracy Levels\")\n",
    "        plt.ylabel(\"PSS Values\")\n",
    "        plt.show()\n",
    "                \n",
    "            \n",
    "        #Create a density plot:\n",
    "        # Flatten the RMSE table values into a 1D array\n",
    "        rmse_values = rmse_table.values.flatten().round()\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.kdeplot(rmse_values, shade=True, color='skyblue', bw_adjust=0.5)\n",
    "\n",
    "        # Add annotated vertical lines based on RMSE values from the table\n",
    "        # Assuming these are the RMSE values where you want the lines\n",
    "        rmse_table['RMSE'] = pd.to_numeric(lowest_rmse_table['RMSE'], errors='coerce')\n",
    "        rmse_line_values = lowest_rmse_table['RMSE'].tolist()\n",
    "\n",
    "        # Plot vertical lines and annotate\n",
    "        for value in rmse_line_values:\n",
    "            plt.axvline(x=value, color='red', linestyle='--', linewidth=1)\n",
    "            plt.text(value + 0.2, 0.002, f'RMSE = {value:.0f}', color='red', rotation=45)\n",
    "\n",
    "        # Add title and labels\n",
    "        plt.title(\"Density Plot of RMSE Values with Annotated Vertical Lines\")\n",
    "        plt.xlabel(\"RMSE Value\")\n",
    "        plt.ylabel(\"Density\")\n",
    "        filename = './Simulated_participant_trajectory_plots/' +participant_id + 'trajectory.png'\n",
    "        plt.savefig(filename)\n",
    "        # Display the plot\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        # Create a scatter plot\n",
    "        rmse_table_reset = rmse_table.reset_index()\n",
    "\n",
    "        # Melt the DataFrame so that each row corresponds to an (accuracy, RMSE) pair with a PSS value\n",
    "        rmse_table_melted = rmse_table_reset.melt(id_vars=['PSS_value'], var_name='Accuracy_Level', value_name='RMSE')\n",
    "\n",
    "        # Create the scatter plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        # Use seaborn's scatterplot with color mapped to PSS_value\n",
    "        sns.scatterplot(data=rmse_table_melted, x='Accuracy_Level', y='RMSE', hue='PSS_value', palette='viridis', s=100, marker='o')\n",
    "\n",
    "        # Add labels and title\n",
    "        plt.title(\"Accuracy vs RMSE (Colored by PSS Value)\", fontsize=16)\n",
    "        plt.xlabel(\"Accuracy Level\", fontsize=14)\n",
    "        plt.ylabel(\"RMSE\", fontsize=14)\n",
    "\n",
    "        # Show the plot\n",
    "        plt.legend(title='PSS Value', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "    return pred_pss_value, pred_accuracy, rmse, rmse_table \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb521d1e-94f6-49fc-96f4-35586ae2a8cd",
   "metadata": {},
   "source": [
    "SIMULATED SAMPLE: Function to get p-value of rmse for allocated PSS, relative to the null, for each participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342bc3e0-8f30-483b-851d-d7673bb53e84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_p_values(participant_data, df_vector_across_slices, plotting=False):\n",
    "    p_values = []\n",
    "    \n",
    "    for idx, participant in participant_data.iterrows():\n",
    "        participant_rmse = participant['RMSE']\n",
    "        participant_pss = participant['Pred_PSS_Value']\n",
    "        participant_accuracy = participant['Pred_Accuracy']\n",
    "        \n",
    "        # Extract the corresponding distribution from df_vector_across_slices\n",
    "        try:\n",
    "            null_vector = df_vector_across_slices.loc[participant_pss, participant_accuracy]\n",
    "            null_vector = [x for x in null_vector if not np.isnan(x)]  # Remove NaNs if any\n",
    "        except KeyError:\n",
    "            print(f\"Warning: PSS={participant_pss}, Accuracy={participant_accuracy} not found in df_vector_across_slices.\")\n",
    "            p_values.append(np.nan)\n",
    "            continue\n",
    "        \n",
    "        if len(null_vector) < 30:\n",
    "            #print(f\"Insufficient data for PSS={participant_pss}, Accuracy={participant_accuracy}.\")\n",
    "            # Assign p-value as 1/10,000 if there's no data (extremely unlikely)\n",
    "            print(f\"Extreme case: PSS={participant_pss}, Accuracy={participant_accuracy} Participant RMSE of {participant_rmse:.2f} is out of range of the null distribution.\")\n",
    "            p_values.append(1/10000)  # Reflect extreme unlikeliness\n",
    "            continue\n",
    "        \n",
    "        # Calculate mean and std deviation of the null distribution\n",
    "        mean_null = np.mean(null_vector)\n",
    "        std_null = np.std(null_vector, ddof=1)  # Sample std deviation\n",
    "        \n",
    "        # Calculate one-tailed p-value (Pr(X < participant_rmse))\n",
    "        p_value = norm.cdf(participant_rmse, loc=mean_null, scale=std_null)\n",
    "        \n",
    "        p_values.append(p_value)\n",
    "        \n",
    "        # Optional plotting\n",
    "        if plotting:\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.histplot(null_vector, bins=50, kde=True, color='#F27B5A', label='Null Distribution', alpha=0.1)\n",
    "            plt.axvline(participant_rmse, color='red', linestyle='--', linewidth=2, label=f'Participant RMSE ({participant_rmse:.2f})')\n",
    "            plt.title(f'Participant RMSE vs Null Distribution\\nPSS={participant_pss}, Accuracy={participant_accuracy}, p-value={p_value:.3f}')\n",
    "            plt.xlabel('RMSE')\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.legend()\n",
    "            plt.close()  # Close the plot to suppress showing\n",
    "    \n",
    "    # Add p-values to the participant_data DataFrame\n",
    "    participant_data['p_value'] = p_values\n",
    "    return participant_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a473d4-b097-409c-9201-337b6fbdd8b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "SIMULATED SAMPLE: Function to get p-value of rmse for known PSS, relative to the null, for each participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6140ec-2605-4972-a0ee-e100aacfec28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_p_values_true(participant_data, df_vector_across_slices, plotting=False):\n",
    "    p_values = []\n",
    "    \n",
    "    for idx, participant in participant_data.iterrows():\n",
    "        participant_rmse = participant['True_RMSE']\n",
    "        participant_pss = participant['PSS_value']\n",
    "        participant_accuracy = participant['Accuracy']\n",
    "        \n",
    "        # Extract the corresponding distribution from df_vector_across_slices\n",
    "        try:\n",
    "            null_vector = df_vector_across_slices.loc[participant_pss, participant_accuracy]\n",
    "            null_vector = [x for x in null_vector if not np.isnan(x)]  # Remove NaNs if any\n",
    "        except KeyError:\n",
    "            print(f\"Warning: PSS={participant_pss}, Accuracy={participant_accuracy} not found in df_vector_across_slices.\")\n",
    "            p_values.append(np.nan)\n",
    "            continue\n",
    "        \n",
    "        if len(null_vector) < 30:\n",
    "            #print(f\"Insufficient data for PSS={participant_pss}, Accuracy={participant_accuracy}.\")\n",
    "            # Assign p-value as 1/10,000 if there's no data (extremely unlikely)\n",
    "            print(f\"Extreme case: PSS={participant_pss}, Accuracy={participant_accuracy} Participant RMSE of {participant_rmse:.2f} is out of range of the null distribution.\")\n",
    "            p_values.append(1/10000)  # Reflect extreme unlikeliness\n",
    "            continue\n",
    "        \n",
    "        # Calculate mean and std deviation of the null distribution\n",
    "        mean_null = np.mean(null_vector)\n",
    "        std_null = np.std(null_vector, ddof=1)  # Sample std deviation\n",
    "        \n",
    "        # Calculate one-tailed p-value (Pr(X < participant_rmse))\n",
    "        p_value = norm.cdf(participant_rmse, loc=mean_null, scale=std_null)\n",
    "        \n",
    "        p_values.append(p_value)\n",
    "        \n",
    "        # Optional plotting\n",
    "        if plotting:\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.histplot(null_vector, bins=50, kde=True, color='#F27B5A', label='Null Distribution', alpha=0.1)\n",
    "            plt.axvline(participant_rmse, color='red', linestyle='--', linewidth=2, label=f'Participant RMSE ({participant_rmse:.2f})')\n",
    "            plt.title(f'Participant RMSE vs Null Distribution\\nPSS={participant_pss}, Accuracy={participant_accuracy}, p-value={p_value:.3f}')\n",
    "            plt.xlabel('RMSE')\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.legend()\n",
    "            plt.close()  # Close the plot to suppress showing\n",
    "    \n",
    "    # Add p-values to the participant_data DataFrame\n",
    "    participant_data['p_value'] = p_values\n",
    "    return participant_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec89d91-8a34-41dc-9b9a-7e3e61823c79",
   "metadata": {},
   "source": [
    "Define colour palettes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c237e88-153e-4d7d-9884-763cc856404b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Referenece:\n",
    "null_colors = [\"#B5D5E0\", \"#4A738F\"]\n",
    "null_cmap = LinearSegmentedColormap.from_list(\"custom_heatmap\", null_colors, N=256)\n",
    "data = np.random.rand(10, 10)\n",
    "sns.heatmap(data, cmap=null_cmap)\n",
    "plt.show()\n",
    "\n",
    "#Null:\n",
    "null_colors = [\"#B1DFEE\", \"#5085E1\"]\n",
    "null_cmap = LinearSegmentedColormap.from_list(\"custom_heatmap\", null_colors, N=256)\n",
    "data = np.random.rand(10, 10)\n",
    "sns.heatmap(data, cmap=null_cmap)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Simulated Participants:\n",
    "sim_participant_colors = [\"#EFD0B6\", \"#e86a36\"]\n",
    "sim_participant_cmap = LinearSegmentedColormap.from_list(\"custom_heatmap\", sim_participant_colors, N=256)\n",
    "data = np.random.rand(10, 10)\n",
    "sns.heatmap(data, cmap=sim_participant_cmap)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Real Participants:\n",
    "real_participant_colors = [\"#EEB0C4\", \"#e54e40\"]\n",
    "real_participant_cmap = LinearSegmentedColormap.from_list(\"custom_heatmap\", real_participant_colors, N=256)\n",
    "data = np.random.rand(10, 10)\n",
    "sns.heatmap(data, cmap=real_participant_cmap)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc4648a",
   "metadata": {},
   "source": [
    "# Run analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a20625c",
   "metadata": {},
   "source": [
    "[If all files have been generated click here](#skip-here)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3848be5b-f802-4f98-82dc-a0e23d89f197",
   "metadata": {},
   "source": [
    "REFERENCE SAMPLE: \n",
    "\n",
    "Generate the reference trajectories and get reference matrix (pivot_df)\n",
    "Optional plotting\n",
    "Optional dropping of the first 5 trials\n",
    "\n",
    "For: PSS = 100-400; Accuracy = 0 - 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb77246",
   "metadata": {},
   "source": [
    "⚠️ NOTE ⚠️\n",
    "\n",
    "If you have already run the analysis and you have the following files - skip to below:\n",
    "10000_null_simulations_100_400_pred_pss_accuracy.csv\n",
    "10000_null_simulations_100_400_all_mean_rmse_plot.npy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7051a6-4334-4570-85ec-d33a170d5345",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize DataFrames to store accumulated results\n",
    "final_pred_pss_accuracy = pd.DataFrame(columns=['Participant_ID', 'Pred_PSS_Value', 'Pred_Accuracy', 'RMSE', 'PSS_value', 'Accuracy', 'True_RMSE'])\n",
    "\n",
    "# Define fixed ranges for the structure\n",
    "pred_pss_values = np.arange(100, 401, 50)  # Pred_PSS_Value: 0 to 400, increments of 50\n",
    "pred_accuracies = np.arange(0, 1.1, 0.1).round(1)  # Pred_Accuracy: 0.1 to 1.0, increments of 0.1\n",
    "\n",
    "# Load simulation data\n",
    "simulation_df = pd.read_csv('/PATH/Reference_simulations.tsv', sep='\\t')\n",
    "simulation_df['Staircase_name'] = simulation_df['Staircase_name'].astype(str)\n",
    "#Run reference_matrix function to get PSS and Accuracy trajectories\n",
    "pivot_df = reference_matrix(simulation_df, pred_pss_values,pred_accuracies, drop = True, plots=True)\n",
    "#Save file\n",
    "pivot_df.to_csv(\"Reference_trajectories_100_400.csv\", index=True)  \n",
    "\n",
    "display(HTML(pivot_df.head().to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fd7975",
   "metadata": {},
   "source": [
    "# 🎲 IDENTIFY RANDOM VS NON-RANDOM RESPONSES: Reference Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76187ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_response_counts_df = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(range(0, 100)):  \n",
    "    participants_file = f'/PATH/SIMULATED_NULL/10000_random_participant_simulations_{i}.tsv'\n",
    "    all_null_df = pd.read_csv(participants_file, sep='\\t')\n",
    "\n",
    "    # Get participant IDs\n",
    "    participant_ids = all_null_df['Participant_ID'].unique().tolist()\n",
    "        \n",
    "    # Loop over each participant ID\n",
    "    for participant_id in participant_ids[0:100]:\n",
    "        participants_df = all_null_df[all_null_df['Participant_ID'] == participant_id]\n",
    "        participants_df['Trial'] = participants_df['Trial'].astype(int)\n",
    "        participants_df['Modified_Staircase_name'] = participants_df['Staircase_name'].str[:-2]\n",
    "\n",
    "        # Recode trial numbers\n",
    "        participants_df.loc[:, 'Recode_Trial'] = np.where(\n",
    "            participants_df['Staircase_name'].str.contains('400'),\n",
    "            participants_df['Trial'], \n",
    "            participants_df['Trial'] + 15\n",
    "        )\n",
    "\n",
    "        # Calculate response counts per Staircase_name and Response_code\n",
    "        response_counts_df = compute_response_counts(participants_df, participant_id, i)\n",
    "        null_response_counts_df = pd.concat([null_response_counts_df, response_counts_df], ignore_index=True)\n",
    "\n",
    "print(null_response_counts_df.head())\n",
    "\n",
    "\n",
    "# Create Staircase Group column\n",
    "null_response_counts_df[\"Modified_Staircase_name\"] = null_response_counts_df[\"Staircase_name\"].apply(lambda x: \"100\" if \"100\" in x else \"400\")\n",
    "\n",
    "# Aggregate response counts per participant and staircase group\n",
    "agg_df = null_response_counts_df.groupby([\"participant_id\", \"Modified_Staircase_name\"])[[\"Before_Response\", \"Same_Response\", \"After_Response\"]].sum().reset_index()\n",
    "\n",
    "# Melt the DataFrame for plotting\n",
    "agg_df_melted = agg_df.melt(id_vars=[\"participant_id\", \"Modified_Staircase_name\"], \n",
    "                            value_vars=[\"Before_Response\", \"Same_Response\", \"After_Response\"], \n",
    "                            var_name=\"Response_Type\", \n",
    "                            value_name=\"Count\")\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(data=agg_df_melted, x=\"Count\", hue=\"Modified_Staircase_name\", bins=100, kde=False)\n",
    "\n",
    "plt.xlabel(\"Response Counts\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of Response Counts Split by Staircase pair\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "agg_df_melted.describe()\n",
    "\n",
    "\n",
    "def get_participants_outside_range_melted(df, staircase_name):\n",
    "    \"\"\"\n",
    "    Returns a set of participant IDs whose any Count value for the given staircase_name is outside [5, 15]\n",
    "    \"\"\"\n",
    "    filtered = df[df['Modified_Staircase_name'] == staircase_name]\n",
    "    \n",
    "    # Find rows where Count is outside the range [5, 15]\n",
    "    outside_range = filtered[(filtered['Count'] < 5) | (filtered['Count'] > 15)]\n",
    "    \n",
    "    # Return unique participant_ids\n",
    "    return set(outside_range['participant_id'].unique())\n",
    "\n",
    "# Get participants with out-of-range responses for staircase '100'\n",
    "participants_100_outside = get_participants_outside_range_melted(agg_df_melted, '100')\n",
    "print(f\"Participants with values outside [5, 15] for staircase '100': {len(participants_100_outside)}\")\n",
    "print(f\"Percentage of total participants: {(len(participants_100_outside)/agg_df_melted['participant_id'].nunique())*100:.2f}%\")\n",
    "\n",
    "# Get participants with out-of-range responses for staircase '400'\n",
    "participants_400_outside = get_participants_outside_range_melted(agg_df_melted, '400')\n",
    "print(f\"Participants with values outside [5, 15] for staircase '400': {len(participants_400_outside)}\")\n",
    "print(f\"Percentage of total participants: {(len(participants_400_outside)/agg_df_melted['participant_id'].nunique())*100:.2f}%\")\n",
    "\n",
    "# Unique participants across either staircase type\n",
    "unique_outside = participants_100_outside.union(participants_400_outside)\n",
    "print(f\"\\nUnique participants with out-of-range values in either staircase: {len(unique_outside)}\")\n",
    "\n",
    "# Percentage of total unique participants\n",
    "total_participants = agg_df_melted['participant_id'].nunique()\n",
    "perc_outside = (len(unique_outside) / total_participants) * 100\n",
    "print(f\"Percentage of total participants: {perc_outside:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8195006-185e-46ef-8a6a-0ba1a6456851",
   "metadata": {},
   "source": [
    "# 🧠 IDENTIFY COGNITIVE STRATEGY: Reference Sample\n",
    "\n",
    "Check if trajectories are parallel; diverging; converging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829156ea-a101-43f3-9421-4fbaac54f927",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "null_diff_df = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(range(0,100)):  \n",
    "    participants_file = f'/PATH/SIMULATED_NULL/10000_random_participant_simulations_{i}.tsv'\n",
    "    all_null_df = pd.read_csv(participants_file, sep='\\t')\n",
    "\n",
    "    # Get participant IDs\n",
    "    participant_ids = []\n",
    "    participant_ids = all_null_df['Participant_ID'].unique().tolist()\n",
    "    #print(participant_ids)\n",
    "        \n",
    "    # Loop over each participant ID\n",
    "    for participant_id in participant_ids[0:100]:\n",
    "        participants_df = all_null_df[all_null_df['Participant_ID'] == participant_id]\n",
    "        #print(participants_df)\n",
    "        participants_df = participants_df.copy()\n",
    "        participants_df.loc[:, 'Trial'] = participants_df['Trial'].astype(int)\n",
    "        participants_df.loc[:, 'Modified_Staircase_name'] = participants_df['Staircase_name'].str[:-2]\n",
    "        participants_df.loc[:, 'Recode_Trial'] = np.where(\n",
    "            participants_df['Staircase_name'].str.contains('400'),\n",
    "            participants_df['Trial'], \n",
    "            participants_df['Trial'] + 15\n",
    "        )\n",
    "\n",
    "        #print(participants_df)\n",
    "\n",
    "         # For 400ms (trials 1-15)\n",
    "        mean_delays_400 = participants_df[participants_df['Staircase_name'].str.contains('400')] \\\n",
    "                            .groupby('Recode_Trial')['Current Delay'].mean()\n",
    "\n",
    "        # For 100ms (trials 16-30)\n",
    "        mean_delays_100 = participants_df[participants_df['Staircase_name'].str.contains('100')] \\\n",
    "                            .groupby('Recode_Trial')['Current Delay'].mean()\n",
    "\n",
    "        # Combine the two mean delay series (400_1, 400_2, and 100_1, 100_2) into one DataFrame\n",
    "        mean_delays = pd.concat([mean_delays_400, mean_delays_100])\n",
    "\n",
    "        # Reindex the trials: 1-15 for 400ms, 16-30 for 100ms\n",
    "        mean_delays.index = np.arange(1, 31)\n",
    "\n",
    "        start_diff = mean_delays[1] - mean_delays[16]\n",
    "        end_diff = mean_delays[15] - mean_delays[30]\n",
    "\n",
    "        new_row = pd.DataFrame([{\n",
    "        'Participant_ID': participant_id,\n",
    "        'start_400': mean_delays[1],\n",
    "        'end_400':  mean_delays[15],\n",
    "        'start_100':  mean_delays[16],\n",
    "        'end_100': mean_delays[30],\n",
    "        'start_diff': start_diff,\n",
    "        'end_diff': end_diff\n",
    "        }])\n",
    "\n",
    "        null_diff_df = pd.concat([null_diff_df, new_row], ignore_index=True)\n",
    "\n",
    "#Calculate: The distance moved (-ve = converging; +ve = diverging)\n",
    "null_diff_df['movement'] = null_diff_df['end_diff'] - null_diff_df['start_diff'] \n",
    "\n",
    "# Parallel: End_diff = Start_diff = 300ms\n",
    "null_parallel_movers = null_diff_df[((null_diff_df[\"end_diff\"] == 300) & (null_diff_df[\"end_400\"] != 400))]\n",
    "\n",
    "# Divergent: End_diff > Start_diff \n",
    "null_divergent_movers = null_diff_df[(null_diff_df[\"end_diff\"] >= 301)]\n",
    "\n",
    "# Convergent: End_diff < Start_diff \n",
    "null_converge_movers = null_diff_df[(null_diff_df[\"end_diff\"] < 300)]\n",
    "\n",
    "null_diff_df.to_csv(\"Null_diff_df_100_400.csv\", index=False)  \n",
    "\n",
    "#Summary:\n",
    "print(len(null_parallel_movers),   len(null_parallel_movers)/ len(null_diff_df)*100,'%: Parallel lines')\n",
    "print(len(null_divergent_movers)/ len(null_diff_df)*100,'%: Have directions away from converging i.e. acc less than 0.3')\n",
    "print(len(null_converge_movers)/ len(null_diff_df)*100,'%: Have directions towards converging i.e. acc > than 0.3')\n",
    "print('\\n\\nMean end delay difference of null: ', null_diff_df['end_diff'].mean())\n",
    "print('STD end delay difference of null: ', null_diff_df['end_diff'].std())\n",
    "\n",
    "#Parallel:\n",
    "print('\\n\\nMean end delay of 400 staircase of parallel movers: ', null_parallel_movers['end_400'].mean())\n",
    "print('Mean end delay 100 staircase of parallel movers: ',null_parallel_movers['end_100'].mean())\n",
    "\n",
    "#Divergent:\n",
    "print('\\n\\nMean change from 300ms diff of divergent movers: ',null_divergent_movers['movement'].mean())\n",
    "print('STD change from 300ms diff of divergent movers: ',null_divergent_movers['movement'].std())\n",
    "print('Median end delay difference of divergent movers: ', null_divergent_movers['end_diff'].median())\n",
    "print('Min end delay difference of divergent movers: ',null_converge_movers['end_diff'].min())\n",
    "print('Max end delay difference of divergent movers: ',null_converge_movers['end_diff'].max())\n",
    "\n",
    "#Convergent:\n",
    "print('\\n\\nMean change from 300ms diff of convergent movers: ', null_converge_movers['movement'].mean())\n",
    "print('STF change from 300ms diff of convergent movers: ', null_converge_movers['movement'].std())\n",
    "print('Median end delay difference of convergent movers: ', null_converge_movers['end_diff'].median())\n",
    "print('Mean end delay difference of convergent movers: ',null_converge_movers['end_diff'].mean())\n",
    "print('STD end delay difference of convergent movers: ',null_converge_movers['end_diff'].std())\n",
    "print('Min end delay difference of convergent movers: ',null_converge_movers['end_diff'].min())\n",
    "print('Max end delay difference of convergent movers: ',null_converge_movers['end_diff'].max())\n",
    "count = (null_diff_df['end_diff'] <= 0).sum()\n",
    "print('Number of convergent movers who converge :',count)\n",
    "\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(ref_diff_df['end_diff'].to_numpy(), bins=150, kde=False, color=\"#4A738F\")\n",
    "plt.xlabel(\"End Difference (ms)\", fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "plt.title(\"End difference in \\n Reference Simulations\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.axhspan(299, 301, color='grey', alpha=0.3)\n",
    "plt.axhspan(301, 600, color='lightgrey', alpha=0.3)\n",
    "scatter = sns.scatterplot(\n",
    "    x=ref_diff_df['PSS_Value'],  # Using index as x-axis\n",
    "    y=ref_diff_df[\"end_diff\"],\n",
    "    hue=ref_diff_df[\"Accuracy\"],\n",
    "    palette=\"viridis\",\n",
    "    sizes=(20, 200),  # Adjust size range\n",
    "    edgecolor=\"black\"\n",
    ")\n",
    "plt.xlabel(\"PSS\")\n",
    "plt.ylabel(\"End Difference (ms)\")\n",
    "plt.title(\"End difference in \\n Reference Simulations\")\n",
    "plt.legend(title=\"Accuracy\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a792a0-2b25-4107-b8d0-8fcdb12be3b9",
   "metadata": {},
   "source": [
    "# ❤️ASSIGN PSS AND ACCURACY VALUES: Reference Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55672f4d-abec-415d-8cad-04ae91d81690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_mean_dfs = []\n",
    "\n",
    "for i in tqdm(range(0,100)):  \n",
    "    participants_file = f'/PATH/SIMULATED_NULL/10000_random_participant_simulations_{i}.tsv'\n",
    "    participants_df = pd.read_csv(participants_file, sep='\\t')\n",
    "    participants_df['Trial'] = participants_df['Trial'].astype(int)\n",
    "    participants_df['Modified_Staircase_name'] = participants_df['Staircase_name'].str[:-2]\n",
    "    \n",
    "    # Recode trial numbers\n",
    "    participants_df.loc[:, 'Recode_Trial'] = np.where(\n",
    "        participants_df['Staircase_name'].str.contains('400'),\n",
    "        participants_df['Trial'], \n",
    "        participants_df['Trial'] + 15\n",
    "    )\n",
    "    \n",
    "    # Get participant IDs\n",
    "    participant_ids = participants_df['Participant_ID'].unique().tolist()\n",
    "    \n",
    "    # Temporary storage for current iteration's results\n",
    "    Pred_PSS_Accuracy = pd.DataFrame(columns=['Participant_ID', 'Pred_PSS_Value', 'Pred_Accuracy', 'RMSE'])\n",
    "    rmse_all_table = pd.DataFrame()\n",
    "    \n",
    "    # Loop over each participant ID\n",
    "    for participant_id in participant_ids[0:100]:\n",
    "        # Call your participant_matrix function (assume it's already defined elsewhere)\n",
    "        pred_pss_value, pred_accuracy, rmse, rmse_table = participant_matrix(\n",
    "            participants_df, participant_id, pivot_df, drop=True, plots=False, verbose=False\n",
    "        )\n",
    "        \n",
    "        # Append results to Pred_PSS_Accuracy\n",
    "        Pred_PSS_Accuracy = Pred_PSS_Accuracy.append({\n",
    "            'Participant_ID': participant_id,\n",
    "            'Pred_PSS_Value': pred_pss_value,\n",
    "            'Pred_Accuracy': pred_accuracy,\n",
    "            'RMSE': rmse\n",
    "        }, ignore_index=True)\n",
    "        \n",
    "        # Append results to rmse_all_table\n",
    "        #rmse_table['Participant_ID'] = participant_id\n",
    "        #rmse_all_table = pd.concat([rmse_all_table, rmse_table], ignore_index=False)  \n",
    "    \n",
    "    # Create group structure for aligning means\n",
    "    group_structure = pd.DataFrame(\n",
    "        [(v, a) for v in pred_pss_values for a in pred_accuracies],\n",
    "        columns=['Pred_PSS_Value', 'Pred_Accuracy']\n",
    "    )\n",
    "    \n",
    "    # Group by and calculate means\n",
    "    grouped_rmse_mean = Pred_PSS_Accuracy.groupby([\"Pred_PSS_Value\", \"Pred_Accuracy\"])[\"RMSE\"].mean().reset_index()\n",
    "    file_mean = group_structure.merge(grouped_rmse_mean, on=['Pred_PSS_Value', 'Pred_Accuracy'], how='left')\n",
    "\n",
    "    # Pivot to create mean_df\n",
    "    mean_df = file_mean.pivot(index=\"Pred_PSS_Value\", columns=\"Pred_Accuracy\", values=\"RMSE\")\n",
    "\n",
    "    # Convert mean_df to a slice of the 3D matrix\n",
    "    slice_matrix = np.full((len(pred_pss_values), len(pred_accuracies)), np.nan)\n",
    "    for pss_val, row in mean_df.iterrows():\n",
    "        for acc_val, rmse in row.items():\n",
    "            if not np.isnan(rmse):\n",
    "                slice_matrix[pss_index[pss_val], accuracy_index[acc_val]] = rmse\n",
    "\n",
    "    # Add the slice to the list\n",
    "    all_mean_dfs.append(slice_matrix)\n",
    "    # Add list of PSS_Accuracy to mega list\n",
    "    final_pred_pss_accuracy = pd.concat([final_pred_pss_accuracy, Pred_PSS_Accuracy], ignore_index=True)\n",
    "    \n",
    "    \n",
    "    final_pred_pss_accuracy.to_csv(\"10000_null_simulations_100_400_pred_pss_accuracy.csv\", index=False)  \n",
    "\n",
    "np.save('/PATH/10000_null_simulations_100_400_all_mean_rmse_plot.npy', all_mean_dfs)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3efca13-d523-49f0-907a-004cfa4a532b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create frequency counts for Predicted Accuracy vs. Predicted PSS Value\n",
    "grouped_pred = null_pred_pss_accuracy.groupby([\"Pred_PSS_Value\", \"Pred_Accuracy\"]).size().reset_index(name=\"Frequency\")\n",
    "\n",
    "# Pivot the table for heatmap structure\n",
    "heatmap_data_pred = grouped_pred.pivot(index=\"Pred_PSS_Value\", columns=\"Pred_Accuracy\", values=\"Frequency\").fillna(0)\n",
    "heatmap_data_pred = heatmap_data_pred.iloc[::-1]\n",
    "\n",
    "fig_width_cm = 8\n",
    "fig_height_cm = 6\n",
    "fig_size_in = (fig_width_cm / 2.54, fig_height_cm / 2.54)\n",
    "\n",
    "# Define full range of accuracy values: 0 to 100 in steps of 10\n",
    "full_accuracy_vals = np.arange(0, 101, 10)\n",
    "full_accuracy_props = full_accuracy_vals / 100\n",
    "\n",
    "# Ensure all expected columns are represented in the heatmap\n",
    "heatmap_data_pred = heatmap_data_pred.reindex(columns=full_accuracy_props, fill_value=0)\n",
    "\n",
    "# Plot heatmap for Predicted Accuracy vs. Predicted PSS Value\n",
    "plt.figure(figsize=fig_size_in, dpi=300)\n",
    "ax = sns.heatmap(\n",
    "    heatmap_data_pred, \n",
    "    cmap=null_cmap, \n",
    "    annot=True, \n",
    "    fmt=\".0f\", \n",
    "    vmin=0, \n",
    "    vmax=1000, \n",
    "    annot_kws={\"size\": 5},\n",
    "    cbar_kws={\"label\": \"Frequency of sample\"}\n",
    ")\n",
    "\n",
    "ax.set_xticks(np.arange(len(full_accuracy_vals)) + 0.5)\n",
    "ax.set_xticklabels(full_accuracy_vals, fontsize=7)\n",
    "ax.set_yticklabels(ax.get_yticklabels(), fontsize=7)\n",
    "ax.set_xlabel(\"Predicted Accuracy (%)\", fontsize=7)\n",
    "ax.set_ylabel(\"Predicted PSS Value (ms)\", fontsize=7)\n",
    "ax.collections[0].colorbar.ax.tick_params(labelsize=7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"10000_null_simulations_100_400_pred_pss_accuracy.png\")\n",
    "plt.show()\n",
    "\n",
    "# --- Mean RMSE heatmap ---\n",
    "null_mean_across_slices = np.nanmean(all_mean_dfs, axis=0)\n",
    "null_mean_df_result = pd.DataFrame(\n",
    "    null_mean_across_slices,\n",
    "    index=pred_pss_values,\n",
    "    columns=pred_accuracies\n",
    ")\n",
    "null_mean_df_result = null_mean_df_result.reindex(columns=full_accuracy_props, fill_value=0).iloc[::-1]\n",
    "\n",
    "plt.figure(figsize=fig_size_in, dpi=300)\n",
    "ax2 = sns.heatmap(\n",
    "    null_mean_df_result, \n",
    "    annot=True, \n",
    "    fmt=\".1f\", \n",
    "    cmap=null_cmap,  \n",
    "    annot_kws={\"size\": 5},\n",
    "    cbar_kws={'label': 'Mean RMSE'}, \n",
    "    vmin=0\n",
    ")\n",
    "\n",
    "ax2.set_xticks(np.arange(len(full_accuracy_vals)) + 0.5)\n",
    "ax2.set_xticklabels(full_accuracy_vals, fontsize=7)\n",
    "ax2.set_yticklabels(ax2.get_yticklabels(), fontsize=7)\n",
    "ax2.set_xlabel(\"Predicted Accuracy (%)\", fontsize=7)\n",
    "ax2.set_ylabel(\"Predicted PSS Value (ms)\", fontsize=7)\n",
    "ax2.collections[0].colorbar.ax.tick_params(labelsize=7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"10000_null_simulations_mean_RMSE_across_slices.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6ddab8-19c2-466e-86f3-fab20c709c71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## PLOTS FOR THE NULL DISTRIBUTION \n",
    "# Initialize an empty list to store the result\n",
    "vector_across_slices = []\n",
    "\n",
    "# Loop over each (y, x) position (same logic as in the original code)\n",
    "for y in range(null_mean_df_result.shape[1]):  # 12 rows\n",
    "    row = []\n",
    "    for x in range(null_mean_df_result.shape[2]):  # 11 columns\n",
    "        values_at_pos = null_mean_df_result[:, y, x].tolist()\n",
    "        row.append(values_at_pos)\n",
    "    vector_across_slices.append(row)\n",
    "\n",
    "df_vector_across_slices = pd.DataFrame(vector_across_slices)\n",
    "df_vector_across_slices.index = pred_pss_values  # Assuming `pred_pss_values` is the list of index labels\n",
    "df_vector_across_slices.columns = pred_accuracies  # Assuming `pred_accuracies` is the list of column labels\n",
    "\n",
    "# Set the number of rows and columns for the grid of subplots\n",
    "num_rows = df_vector_across_slices.shape[0]\n",
    "num_cols = df_vector_across_slices.shape[1]\n",
    "\n",
    "# Calculate the min/max values for the x and y axis ranges\n",
    "min_xvalue = 0\n",
    "max_xvalue = math.ceil(np.nanmax([item for sublist in df_vector_across_slices.values for item in sublist]) + 0.05)\n",
    "max_yvalue = 0\n",
    "\n",
    "# Find max frequency for scaling y-axis\n",
    "for cell_row in range(num_rows):\n",
    "    for cell_col in range(num_cols):\n",
    "        cell_values = df_vector_across_slices.iloc[cell_row, cell_col]\n",
    "        hist, bin_edges = np.histogram(cell_values, bins=50, range=(min_xvalue, max_xvalue))\n",
    "        max_yvalue = max(max_yvalue, hist.max())\n",
    "\n",
    "# Create figure and axes for subplots\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(15,10))\n",
    "\n",
    "# Loop through each subplot to create histograms\n",
    "for cell_row in range(num_rows):\n",
    "    for cell_col in range(num_cols):\n",
    "        cell_values = df_vector_across_slices.iloc[cell_row, cell_col]\n",
    "        ax = axes[num_rows - 1 - cell_row, cell_col]  # Flip the row order\n",
    "\n",
    "        # Plot the histogram for the null distribution\n",
    "        sns.histplot(cell_values, bins=50, kde=True, color='#5085E1', edgecolor='#5085E1', alpha=0.7, ax=ax, \n",
    "                     binrange=(min_xvalue, max_xvalue))\n",
    "        \n",
    "        # Remove axis labels and ticks for a clean look\n",
    "        ax.set_xticks([]) \n",
    "        ax.set_yticks([]) \n",
    "        ax.set_ylabel('')\n",
    "\n",
    "        # Set axis limits\n",
    "        ax.set_xlim(min_xvalue, max_xvalue)\n",
    "        ax.set_ylim(0, max_yvalue)\n",
    "\n",
    "        # Clean grid appearance\n",
    "        if cell_col == num_cols - 1:\n",
    "            ax.spines['top'].set_visible(True)\n",
    "            ax.spines['right'].set_visible(True)\n",
    "            ax.spines['left'].set_visible(True)\n",
    "            ax.spines['bottom'].set_visible(True)\n",
    "        else:\n",
    "            ax.spines['top'].set_visible(True)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "            ax.spines['left'].set_visible(True)\n",
    "            ax.spines['bottom'].set_visible(True)\n",
    "\n",
    "        if cell_row == 0 and cell_col == 0:\n",
    "            ax.set_xticks(np.linspace(min_xvalue, max_xvalue, num=2))\n",
    "        else:\n",
    "            ax.set_xticks([])\n",
    "\n",
    "        if cell_col == 0 and cell_row == 0:\n",
    "            ax.set_yticks(np.linspace(0, max_yvalue, num=2))\n",
    "\n",
    "# Left Y-axis (Pred_PSS_Value)\n",
    "ax_left = fig.add_axes([0.065, 0.1, 0.01, 0.75])\n",
    "ax_left.set_xticks([])  \n",
    "ax_left.tick_params(axis=\"y\", direction=\"out\", length=12, width=1.2)\n",
    "ax_left.set_yticks(np.arange(num_rows) + 0.5)\n",
    "ax_left.set_yticklabels(pred_pss_values, fontsize=10, ha='right')\n",
    "ax_left.set_ylabel(\"Predicted PSS Value\\nNumber of instances\", fontsize=12, labelpad=20)\n",
    "ax_left.tick_params(left=False, labelleft=True, right=False, labelright=False)\n",
    "ax_left.spines['top'].set_visible(False)\n",
    "ax_left.spines['bottom'].set_visible(False)\n",
    "ax_left.spines['left'].set_visible(False)\n",
    "ax_left.spines['right'].set_visible(False)\n",
    "\n",
    "# Bottom X-axis (Pred_Accuracy)\n",
    "ax_bottom = fig.add_axes([0.16, 0.06, 0.7, 0.01])\n",
    "ax_bottom.set_yticks([])  \n",
    "ax_bottom.set_xticks(np.arange(num_cols))\n",
    "ax_bottom.set_xticklabels(pred_accuracies, rotation=0, fontsize=10, ha='center')\n",
    "ax_bottom.set_xlabel(\"RMSE\\nPredicted Accuracy\", fontsize=12, labelpad=15)\n",
    "ax_bottom.tick_params(axis=\"x\", direction=\"inout\", length=6, width=1.2)\n",
    "ax_bottom.spines['top'].set_visible(False)\n",
    "ax_bottom.spines['bottom'].set_visible(False)\n",
    "ax_bottom.spines['left'].set_visible(False)\n",
    "ax_bottom.spines['right'].set_visible(False)\n",
    "\n",
    "# Adjust layout to fit the grid tightly\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.savefig(\"Null_distribution_plots.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bc2d62",
   "metadata": {},
   "source": [
    "# 🎲 IDENTIFY RANDOM VS NON-RANDOM RESPONSES: Simulated Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44260081-9ede-482a-b09e-33568c3ad030",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sim_participant_response_counts_df = pd.DataFrame()\n",
    "\n",
    "sim_participants_file = f'/PATH/10000_simulated_participants.tsv'\n",
    "sim_participants_df = pd.read_csv(sim_participants_file, sep='\\t')\n",
    "\n",
    "sim_participants_df['Trial'] = sim_participants_df['Trial'].astype(int)\n",
    "sim_participants_df['Modified_Staircase_name'] = sim_participants_df['Staircase_name'].str[:-2]\n",
    "\n",
    "# Recode trial numbers\n",
    "sim_participants_df.loc[:, 'Recode_Trial'] = np.where(\n",
    "    sim_participants_df['Staircase_name'].str.contains('400'),\n",
    "    sim_participants_df['Trial'], \n",
    "    sim_participants_df['Trial'] + 15\n",
    ")\n",
    "# Get participant IDs\n",
    "participant_ids = sim_participants_df['Participant_ID'].unique().tolist()\n",
    "#print(participant_ids)\n",
    "\n",
    "# Loop over each participant ID\n",
    "for participant_id in tqdm(range(1,10001)):\n",
    "    ID_string = 'Participant_' + str(participant_id)\n",
    "    participants_df = sim_participants_df[sim_participants_df['Participant_ID'] == ID_string]\n",
    "    #print(participants_df)\n",
    "\n",
    "    participants_df['Trial'] = participants_df['Trial'].astype(int)\n",
    "    participants_df['Modified_Staircase_name'] = participants_df['Staircase_name'].str[:-2]\n",
    "    \n",
    "    # Recode trial numbers\n",
    "    participants_df.loc[:, 'Recode_Trial'] = np.where(\n",
    "        participants_df['Staircase_name'].str.contains('400'),\n",
    "        participants_df['Trial'], \n",
    "        participants_df['Trial'] + 15\n",
    "    )\n",
    "    \n",
    "    # Get participant IDs\n",
    "    #participant_data = participants_df[participants_df['Participant_ID'] == participant_id]\n",
    "\n",
    "    # Calculate response counts per Staircase_name and Response_code\n",
    "    response_counts_df = compute_response_counts_simulated_participants(participants_df, participant_id)\n",
    "    sim_participant_response_counts_df = pd.concat([sim_participant_response_counts_df, response_counts_df], ignore_index=True)\n",
    "\n",
    "print(sim_participant_response_counts_df.head())\n",
    "sim_participant_response_counts_df.to_csv('sim_participant_response_counts_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5caf6ea-e149-46d0-9d15-c9b60f22ef6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create the 'Modified_Staircase_name' column for null_response_counts_df\n",
    "null_response_counts_df['Modified_Staircase_name'] = null_response_counts_df['Staircase_name'].str[:-2]\n",
    "\n",
    "# Separate the data into two groups based on the 'Modified_Staircase_name' prefix\n",
    "df_100_null = null_response_counts_df[null_response_counts_df['Modified_Staircase_name'].str.startswith('100')]\n",
    "df_400_null = null_response_counts_df[null_response_counts_df['Modified_Staircase_name'].str.startswith('400')]\n",
    "\n",
    "# Group by participant_id and Modified_Staircase_name, and sum the responses\n",
    "summed_100_null = df_100_null.groupby(['participant_id', 'Modified_Staircase_name'])[['Before_Response', 'Same_Response', 'After_Response']].sum()\n",
    "summed_400_null = df_400_null.groupby(['participant_id', 'Modified_Staircase_name'])[['Before_Response', 'Same_Response', 'After_Response']].sum()\n",
    "\n",
    "# Now we concatenate the results for both 100 and 400 staircases\n",
    "combined_sums_null = pd.concat([summed_100_null, summed_400_null], axis=0)\n",
    "combined_sums_null.reset_index(inplace=True)\n",
    "\n",
    "# Pivot the table so that each participant has one row, and each staircase is a separate column\n",
    "pivoted_null_df = combined_sums_null.pivot_table(index='participant_id', \n",
    "                                                 columns='Modified_Staircase_name', \n",
    "                                                 values=['Before_Response', 'Same_Response', 'After_Response'], \n",
    "                                                 aggfunc='sum')\n",
    "\n",
    "\n",
    "pivoted_null_df.columns = ['_'.join(col).strip() for col in pivoted_null_df.columns.values]\n",
    "#print(pivoted_null_df.head())\n",
    "\n",
    "mean_null_row = pivoted_null_df.mean().to_frame().T\n",
    "mean_null_row.index = ['Null']  # Rename the index to 'Null'\n",
    "\n",
    "# Now merge the mean row with the pivoted_df (participant's data)\n",
    "pivoted_df_with_null = pd.concat([pivoted_df, mean_null_row])\n",
    "# Show the resulting DataFrame\n",
    "#print(pivoted_df_with_null)\n",
    " \n",
    " \n",
    " \n",
    "sim_participant_response_counts_df = pd.read_csv('sim_participant_response_counts_df.csv')\n",
    "sim_participant_response_counts_df['Modified_Staircase_name'] = sim_participant_response_counts_df['Staircase_name'].str[:-2]\n",
    "#print(sim_participant_response_counts_df)\n",
    "\n",
    "# Separate the data into two groups based on the 'Modified_Staircase_name' prefix\n",
    "df_100 = sim_participant_response_counts_df[sim_participant_response_counts_df['Modified_Staircase_name'].str.startswith('100')]\n",
    "df_400 = sim_participant_response_counts_df[sim_participant_response_counts_df['Modified_Staircase_name'].str.startswith('400')]\n",
    "#print(df_100)\n",
    "\n",
    "# Group by participant_id and Modified_Staircase_name, and sum the responses\n",
    "summed_100 = df_100.groupby(['participant_id', 'Modified_Staircase_name'])[['Before_Response', 'Same_Response', 'After_Response']].sum()\n",
    "summed_400 = df_400.groupby(['participant_id', 'Modified_Staircase_name'])[['Before_Response', 'Same_Response', 'After_Response']].sum()\n",
    "\n",
    "# Now we concatenate the results for both 100 and 400 staircases\n",
    "combined_sums = pd.concat([summed_100, summed_400], axis=0)\n",
    "\n",
    "# Reset index to make 'participant_id' and 'Modified_Staircase_name' regular columns\n",
    "combined_sums.reset_index(inplace=True)\n",
    "\n",
    "# Pivot the table so that each participant has one row, and each staircase is a separate column\n",
    "pivoted_df = combined_sums.pivot_table(index='participant_id', \n",
    "                                       columns='Modified_Staircase_name', \n",
    "                                       values=['Before_Response', 'Same_Response', 'After_Response'], \n",
    "                                       aggfunc='sum')\n",
    "\n",
    "# Flatten the multi-index columns\n",
    "pivoted_df.columns = ['_'.join(col).strip() for col in pivoted_df.columns.values]\n",
    "#print(pivoted_df)\n",
    "\n",
    "\n",
    "# Get participants whose any response values for staircase '100' fall outside the range [5, 15]\n",
    "participants_100_outside_range = count_participants_with_values_outside_range_for_staircase_type(pivoted_df_with_null, staircase_type='100')\n",
    "print(f\"Participants with any response values outside the range [5, 15] for staircase '100': {len(participants_100_outside_range)}\")\n",
    "\n",
    "# Get participants whose any response values for staircase '400' fall outside the range [5, 15]\n",
    "participants_400_outside_range = count_participants_with_values_outside_range_for_staircase_type(pivoted_df_with_null, staircase_type='400')\n",
    "print(f\"Participants with any response values == or outside the range [5, 15] for staircase '400': {len(participants_400_outside_range)}\")\n",
    "\n",
    "# Get all unique participants whose any response values fall outside the range [5, 15] for either staircase type\n",
    "overall_outside_range_participants = count_overall_outside_range(pivoted_df_with_null)\n",
    "print(f\"\\nOverall unique participants with any response values == or outside the range [5, 15] (for both '100' or '400'): {len(overall_outside_range_participants)}\")\n",
    "\n",
    "print(\"\\nNumber of unique participants who meet the condition (either or both staircase types):\")\n",
    "perc = (len(overall_outside_range_participants)/ len(pivoted_df)) * 100\n",
    "print(perc, '%')\n",
    "\n",
    "# Optionally print the actual IDs of participants\n",
    "#print(\"Unique participants who meet the condition (either or both staircase types):\")\n",
    "#print(overall_outside_range_participants)\n",
    "\n",
    "\n",
    "#participant_response_counts_df\n",
    "all_ids = set(sim_participant_response_counts_df['participant_id'].astype(str))\n",
    "keep_ids = set(overall_outside_range_participants)\n",
    "\n",
    "all_ids = set(sim_participant_response_counts_df['participant_id'].astype(str))\n",
    "keep_ids = set(str(k) for k in overall_outside_range_participants)\n",
    "\n",
    "# Get those NOT in overall_outside_range_participants\n",
    "exclude_ids_random = list(all_ids - keep_ids)\n",
    "#print('Exclude: ', exclude_ids_random)\n",
    "print('Exclude: ', len(exclude_ids_random), (len(exclude_ids_random))/10000*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dbd9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_colors = ['#87afe6', '#b1d8ec', '#6991e1']\n",
    "sim_colors = ['#e49971', '#ecd1b7', '#e17a4b']\n",
    "\n",
    "def get_cols_by_response_and_staircase(df, response_type, staircase_prefix):\n",
    "    # Return list of columns matching exact pattern ResponseType_StaircasePrefix\n",
    "    return [col for col in df.columns if col == f\"{response_type}_{staircase_prefix}\"]\n",
    "\n",
    "# Plot for 100 staircases\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, response in enumerate(['Before_Response', 'Same_Response', 'After_Response']):\n",
    "    cols = get_cols_by_response_and_staircase(pivoted_null_df, response, '100')\n",
    "    if len(cols) == 0:\n",
    "        print(f\"No columns found for {response} 100\")\n",
    "        continue\n",
    "    # cols is a list with one element (the exact column name)\n",
    "    sns.kdeplot(pivoted_null_df[cols[0]], fill=True, alpha=0.3, color=null_colors[i], label=f'Null 100 - {response.split(\"_\")[0]}')\n",
    "    sns.kdeplot(pivoted_df[cols[0]], fill=True, alpha=0.3, color=sim_colors[i], label=f'Sim 100 - {response.split(\"_\")[0]}')\n",
    "plt.title(\"KDE of '100' Staircases Responses\")\n",
    "plt.xlabel('Response Value')\n",
    "plt.ylabel('Density')\n",
    "plt.xlim(0, 30)\n",
    "plt.legend()\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot for 400 staircases\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, response in enumerate(['Before_Response', 'Same_Response', 'After_Response']):\n",
    "    cols = get_cols_by_response_and_staircase(pivoted_null_df, response, '400')\n",
    "    if len(cols) == 0:\n",
    "        print(f\"No columns found for {response} 400\")\n",
    "        continue\n",
    "    # cols is a list with one element (the exact column name)\n",
    "    sns.kdeplot(pivoted_null_df[cols[0]], fill=True, alpha=0.3, color=null_colors[i], label=f'Null 400 - {response.split(\"_\")[0]}')\n",
    "    sns.kdeplot(pivoted_df[cols[0]], fill=True, alpha=0.3, color=sim_colors[i], label=f'Sim 400 - {response.split(\"_\")[0]}')\n",
    "plt.title(\"KDE of '400' Staircases Responses\")\n",
    "plt.xlabel('Response Value')\n",
    "plt.ylabel('Density')\n",
    "plt.xlim(0, 30)\n",
    "plt.legend()\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b242b1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set colors\n",
    "null_colors = ['#87afe6', '#b1d8ec', '#6991e1']\n",
    "sim_colors = ['#e49971', '#ecd1b7', '#e17a4b']\n",
    "\n",
    "# Initialize the figure\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot null group responses\n",
    "sns.kdeplot(pivoted_null_df.filter(like='Before_Response').mean(axis=1), \n",
    "            fill=True, color=null_colors[0], alpha=0.3, label='Null - Before')\n",
    "sns.kdeplot(pivoted_null_df.filter(like='Same_Response').mean(axis=1), \n",
    "            fill=True, color=null_colors[1], alpha=0.3, label='Null - Same')\n",
    "sns.kdeplot(pivoted_null_df.filter(like='After_Response').mean(axis=1), \n",
    "            fill=True, color=null_colors[2], alpha=0.3, label='Null - After')\n",
    "\n",
    "# Plot simulated participants group responses\n",
    "sns.kdeplot(pivoted_df.filter(like='Before_Response').mean(axis=1), \n",
    "            fill=True, color=sim_colors[0], alpha=0.3, label='Simulated - Before')\n",
    "sns.kdeplot(pivoted_df.filter(like='Same_Response').mean(axis=1), \n",
    "            fill=True, color=sim_colors[1], alpha=0.3, label='Simulated - Same')\n",
    "sns.kdeplot(pivoted_df.filter(like='After_Response').mean(axis=1), \n",
    "            fill=True, color=sim_colors[2], alpha=0.3, label='Simulated - After')\n",
    "\n",
    "# Plot settings\n",
    "plt.title('KDE of Response Types: Null vs Simulated Participants')\n",
    "plt.xlabel('Sum of Responses')\n",
    "plt.ylabel('Density')\n",
    "plt.xlim(0, 30)\n",
    "plt.legend()\n",
    "sns.despine()  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427a8911",
   "metadata": {},
   "source": [
    "# 🧠 IDENTIFY COGNITIVE STRATEGY: Simulated Sample\n",
    "\n",
    "Check if trajectories are parallel; diverging; converging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944fcb03-e123-4e5d-99d7-c9098761425d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sim_participant_diff_df = pd.DataFrame()\n",
    "\n",
    "sim_participants_file = f'/PATH/10000_simulated_participants.tsv'\n",
    "sim_participants_df = pd.read_csv(sim_participants_file, sep='\\t')\n",
    "print(sim_participants_df)\n",
    "sim_participants_df['Trial'] = sim_participants_df['Trial'].astype(int)\n",
    "sim_participants_df['Modified_Staircase_name'] = sim_participants_df['Staircase_name'].str[:-2]\n",
    "\n",
    "# Recode trial numbers\n",
    "sim_participants_df.loc[:, 'Recode_Trial'] = np.where(\n",
    "    sim_participants_df['Staircase_name'].str.contains('400'),\n",
    "    sim_participants_df['Trial'], \n",
    "    sim_participants_df['Trial'] + 15\n",
    ")\n",
    "\n",
    "# Get participant IDs\n",
    "participant_ids = sim_participants_df['Participant_ID'].unique().tolist()\n",
    "\n",
    "# Loop over each participant ID\n",
    "for participant_id in participant_ids[0:10001]:\n",
    "\n",
    "    participants_df = sim_participants_df[sim_participants_df['Participant_ID'] == participant_id]\n",
    "    participants_df['Trial'] = participants_df['Trial'].astype(int)\n",
    "    participants_df['Modified_Staircase_name'] = participants_df['Staircase_name'].str[:-2]\n",
    "    \n",
    "    # Recode trial numbers\n",
    "    participants_df.loc[:, 'Recode_Trial'] = np.where(\n",
    "        participants_df['Staircase_name'].str.contains('400'),\n",
    "        participants_df['Trial'], \n",
    "        participants_df['Trial'] + 15\n",
    "    )\n",
    "    \n",
    "    # Get participant IDs\n",
    "    participant_ids = participants_df['Participant_ID'].unique().tolist()\n",
    "    \n",
    "\n",
    "     # For 400ms (trials 1-15)\n",
    "    mean_delays_400 = participants_df[participants_df['Staircase_name'].str.contains('400')] \\\n",
    "                        .groupby('Recode_Trial')['Current Delay'].mean()\n",
    "\n",
    "    # For 100ms (trials 16-30)\n",
    "    mean_delays_100 = participants_df[participants_df['Staircase_name'].str.contains('100')] \\\n",
    "                        .groupby('Recode_Trial')['Current Delay'].mean()\n",
    "\n",
    "    # Combine the two mean delay series (400_1, 400_2, and 100_1, 100_2) into one DataFrame\n",
    "    mean_delays = pd.concat([mean_delays_400, mean_delays_100], ignore_index=True)\n",
    "\n",
    "    # Reindex the trials: 1-15 for 400ms, 16-30 for 100ms\n",
    "    mean_delays.index = np.arange(1, 31)\n",
    "\n",
    "    start_diff = mean_delays[1] - mean_delays[16]\n",
    "    end_diff = mean_delays[15] - mean_delays[30]\n",
    "    # Create a new DataFrame row\n",
    "    new_row = pd.DataFrame({\n",
    "        'Participant_ID': [participant_id],\n",
    "        'start_400': [mean_delays[1]],\n",
    "        'end_400': [mean_delays[15]],\n",
    "        'start_100': [mean_delays[16]],\n",
    "        'end_100': [mean_delays[30]],\n",
    "        'start_diff': [start_diff],\n",
    "        'end_diff': [end_diff]\n",
    "    })\n",
    "    \n",
    "    # Concatenate the new row with the existing DataFrame\n",
    "    sim_participant_diff_df = pd.concat([sim_participant_diff_df, new_row], ignore_index=True)\n",
    "\n",
    "#⚠️ IF EXCLUDING PARTICIPANTS WHO HAVE RANDOM BUTTON PRESS: RUN THIS LINE\n",
    "# Convert keep_ids (numbers or strings) to formatted Participant_ID strings\n",
    "keep_ids_str = {f\"Participant_{i}\" for i in keep_ids}\n",
    "\n",
    "# Filter DataFrame by these formatted IDs\n",
    "sim_participant_diff_df = sim_participant_diff_df[\n",
    "    sim_participant_diff_df['Participant_ID'].isin(keep_ids_str)\n",
    "]\n",
    "\n",
    "\n",
    "#Calculate: The distance moved (-ve = converging; +ve = diverging)\n",
    "sim_participant_diff_df['movement'] = sim_participant_diff_df['end_diff'] - sim_participant_diff_df['start_diff'] \n",
    "\n",
    "# Parallel: End_diff = Start_diff = 300ms\n",
    "sim_participant_parallel_movers = sim_participant_diff_df[((sim_participant_diff_df[\"end_diff\"] == 300) & (sim_participant_diff_df[\"end_400\"] != 400))]\n",
    "print(sim_participant_parallel_movers)\n",
    "exclude_ids_parallel = set(sim_participant_parallel_movers['Participant_ID'].astype(str))\n",
    "\n",
    "# Divergent: End_diff > Start_diff \n",
    "sim_participant_divergent_movers = sim_participant_diff_df[(sim_participant_diff_df[\"end_diff\"] >= 301)]\n",
    "\n",
    "# Convergent: End_diff < Start_diff \n",
    "sim_participant_converge_movers = sim_participant_diff_df[(sim_participant_diff_df[\"end_diff\"] < 300)]\n",
    "\n",
    "sim_participant_diff_df.to_csv(\"10000_simulated_participants_diff_df_100_400.csv\", index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d679e534-f762-4153-8be3-a33870cf7fb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(sim_participant_diff_df), 'Simulated participants included')\n",
    "\n",
    "#Summary:\n",
    "print((len(sim_participant_parallel_movers)),':', len(sim_participant_parallel_movers)/ 10000*100,'%: Parallel lines')\n",
    "print((len(sim_participant_divergent_movers)),':',len(sim_participant_divergent_movers)/ 10000*100,'%: Have directions away from converging i.e. acc less than 0.3')\n",
    "print((len(sim_participant_converge_movers)),':',len(sim_participant_converge_movers)/ 10000*100,'%: Have directions towards converging i.e. acc > than 0.3')\n",
    "print('\\n\\nMean end delay difference of sim participants: ', sim_participant_diff_df['end_diff'].mean())\n",
    "print('STD end delay difference of sim participants: ', sim_participant_diff_df['end_diff'].std())\n",
    "\n",
    "#Parallel:\n",
    "print('\\n\\nMean end delay of 400 staircase of parallel movers: ', sim_participant_parallel_movers['end_400'].mean())\n",
    "print('Mean end delay 100 staircase of parallel movers: ',sim_participant_parallel_movers['end_100'].mean())\n",
    "\n",
    "#Divergent:\n",
    "print('\\n\\nMean change from 300ms diff of divergent movers: ',sim_participant_divergent_movers['movement'].mean())\n",
    "print('STD change from 300ms diff of divergent movers: ',sim_participant_divergent_movers['movement'].std())\n",
    "print('Median end delay difference of divergent movers: ', sim_participant_divergent_movers['end_diff'].median())\n",
    "print('Min end delay difference of divergent movers: ',sim_participant_divergent_movers['end_diff'].min())\n",
    "print('Max end delay difference of divergent movers: ',sim_participant_divergent_movers['end_diff'].max())\n",
    "\n",
    "#Convergent:\n",
    "print('\\n\\nMean change from 300ms diff of convergent movers: ', sim_participant_converge_movers['movement'].mean())\n",
    "print('STF change from 300ms diff of convergent movers: ', sim_participant_converge_movers['movement'].std())\n",
    "print('Median end delay difference of convergent movers: ', sim_participant_converge_movers['end_diff'].median())\n",
    "print('Mean end delay difference of convergent movers: ',sim_participant_converge_movers['end_diff'].mean())\n",
    "print('STD end delay difference of convergent movers: ',sim_participant_converge_movers['end_diff'].std())\n",
    "print('Min end delay difference of convergent movers: ',sim_participant_converge_movers['end_diff'].min())\n",
    "print('Max end delay difference of convergent movers: ',sim_participant_converge_movers['end_diff'].max())\n",
    "count = (sim_participant_diff_df['end_diff'] <= 0).sum()\n",
    "print('Number of convergent movers who converge completely :',count)\n",
    "\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(ref_diff_df['end_diff'], bins=150, kde=False, color=\"#478590\")\n",
    "sns.histplot(sim_participant_diff_df['end_diff'], bins=150, kde=False, color=\"#e86a36\")\n",
    "plt.xlabel(\"End Difference (ms)\", fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "plt.title(\"End difference in \\n Reference and Simulated Participant Simulations\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.axhspan(299, 301, color='grey', alpha=0.3)\n",
    "plt.axhspan(301, 600, color='lightgrey', alpha=0.3)\n",
    "scatter = sns.scatterplot(\n",
    "    x=ref_diff_df['PSS_Value'],  # Using index as x-axis\n",
    "    y=ref_diff_df[\"end_diff\"],\n",
    "    hue=ref_diff_df[\"Accuracy\"],\n",
    "    palette=\"viridis\",\n",
    "    sizes=(20, 200),  # Adjust size range\n",
    "    edgecolor=\"black\"\n",
    ")\n",
    "scatter = sns.scatterplot(\n",
    "    x=sim_participant_diff_df['Participant_ID'],  # Using index as x-axis\n",
    "    y=sim_participant_diff_df[\"end_diff\"],\n",
    "    #hue=null_diff_df[\"Accuracy\"],\n",
    "    color=\"#e86a36\",\n",
    "    sizes=(20, 200),  # Adjust size range\n",
    "    edgecolor=\"black\", \n",
    "    alpha = 0.1\n",
    ")\n",
    "plt.xlabel(\"PSS\")\n",
    "plt.ylabel(\"End Difference (ms)\")\n",
    "plt.title(\"End difference in \\n Simulated Participant Simulations\")\n",
    "plt.legend(title=\"Accuracy\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Density Plot: Divergent vs Convergent\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.kdeplot(null_diff_df['end_diff'], color=\"#5085E1\")#, common_norm = True)\n",
    "sns.kdeplot(sim_participant_divergent_movers['end_diff'], color=\"#e86a36\", linestyle=\"--\", kde= False)\n",
    "sns.kdeplot(sim_participant_converge_movers['end_diff'], color=\"#e86a36\", linestyle=\"-\",kde= False)\n",
    "plt.ylim(0, 0.014)\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Difference between mean 400 and 100 staircases at trial 15 (ms)\", fontsize=12)\n",
    "plt.ylabel(\"Density\", fontsize=12)\n",
    "#plt.title(\"Difference between mean 400 and 100 staircases at trial 15 \\n Divergent vs Convergent Simulated Participants\", fontsize=14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc8abad-f1e0-45f0-8e3d-b8addd90f98f",
   "metadata": {},
   "source": [
    "# ❤️ASSIGN PSS AND ACCURACY VALUES: Simulated Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8b1bb0-2a85-4b1e-948c-e3e0a0c02dde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define fixed ranges for the structure\n",
    "pred_pss_values = np.arange(100, 401, 50)  # Pred_PSS_Value: 0 to 400, increments of 50\n",
    "pred_accuracies = np.arange(0, 1.1, 0.1).round(1)  # Pred_Accuracy: 0.0 to 1.0, increments of 0.1\n",
    "\n",
    "\n",
    "correct_columns = [\n",
    "    \"Participant_ID\", \"PSS_value\", \"Accuracy\", \"Staircase_name\", \"Trial\", \n",
    "    \"Current Delay\", \"Button\", \"Response_code\", \"Modified_Staircase_name\", \"Recode_Trial\"\n",
    "]\n",
    "\n",
    "sim_participants_file = f'/PATH/10000_simulated_participants.tsv'\n",
    "sim_participants_df = pd.read_csv(sim_participants_file, sep='\\t', header=None, skiprows=1, names=correct_columns)\n",
    "sim_participants_df['Trial'] = sim_participants_df['Trial'].astype(int)\n",
    "sim_participants_df['Staircase_name'] = sim_participants_df['Staircase_name'].astype(str)\n",
    "sim_participants_df['Modified_Staircase_name'] = sim_participants_df['Staircase_name'].str[:-2]\n",
    "\n",
    "# Recode trial numbers\n",
    "sim_participants_df.loc[:, 'Recode_Trial'] = np.where(\n",
    "    sim_participants_df['Staircase_name'].str.contains('400'),\n",
    "    sim_participants_df['Trial'], \n",
    "    sim_participants_df['Trial'] + 15\n",
    ")\n",
    "\n",
    "# Get participant IDs\n",
    "sim_participant_ids = sim_participants_df['Participant_ID'].unique().tolist()\n",
    "\n",
    "# Temporary storage for current iteration's results\n",
    "Pred_PSS_Accuracy = pd.DataFrame(columns=['Participant_ID', 'Pred_PSS_Value', 'Pred_Accuracy', 'RMSE', 'True_PSS_Value', 'True_Accuracy', 'True_RMSE'])\n",
    "rmse_all_table = pd.DataFrame()\n",
    "final_pred_pss_accuracy = pd.DataFrame()\n",
    "all_mean_dfs = []\n",
    "\n",
    "pss_index = {v: i for i, v in enumerate(pred_pss_values)}\n",
    "accuracy_index = {v: i for i, v in enumerate(pred_accuracies)}\n",
    "\n",
    "#⚠️ IF EXCLUDING PARTICIPANTS WHO HAVE RANDOM BUTTON PRESS A PARALLEL LINES\n",
    "excluded_ids = set(exclude_ids_parallel) | set(exclude_ids_random)\n",
    "\n",
    "\n",
    "# Loop over each participant ID\n",
    "for participant_id in sim_participant_ids[1:10001]:   \n",
    "    # ⚠️ Exclude if participant_id is in either exclusion set\n",
    "    if participant_id in excluded_ids:\n",
    "        print(f\"Skipping excluded participant: {participant_id}\")\n",
    "        continue\n",
    "        \n",
    "    #print(participants_df)\n",
    "    # Call your participant_matrix function (assume it's already defined elsewhere)\n",
    "    pred_pss_value, pred_accuracy, rmse, rmse_table = participant_matrix(\n",
    "        sim_participants_df, participant_id, pivot_df, drop=True, plots=False, verbose=False\n",
    "    )\n",
    "    \n",
    "    #print(rmse_table)\n",
    "    row = sim_participants_df[sim_participants_df[\"Participant_ID\"] == participant_id].iloc[0]  # Take the first occurrence\n",
    "\n",
    "    true_pss_value = row[\"PSS_value\"]\n",
    "    true_accuracy = row[\"Accuracy\"]\n",
    "\n",
    "    # Extract RMSE value\n",
    "    rmse_true = rmse_table.loc[true_pss_value, true_accuracy]\n",
    "\n",
    "    new_row = pd.DataFrame({\n",
    "        'Participant_ID': [participant_id],\n",
    "        'Pred_PSS_Value': [pred_pss_value],\n",
    "        'Pred_Accuracy': [pred_accuracy],\n",
    "        'RMSE': [rmse],\n",
    "        'True_PSS_Value': [true_pss_value],\n",
    "        'True_Accuracy': [true_accuracy],\n",
    "        'True_RMSE': [rmse_true]\n",
    "        })\n",
    "    \n",
    "    # Concatenate the new row with the existing DataFrame\n",
    "    Pred_PSS_Accuracy = pd.concat([Pred_PSS_Accuracy, new_row], ignore_index=True)\n",
    "\n",
    "    # Append results to rmse_all_table\n",
    "    #rmse_table['Participant_ID'] = participant_id\n",
    "    #rmse_all_table = pd.concat([rmse_all_table, rmse_table], ignore_index=False)  \n",
    "\n",
    "# Create group structure for aligning means\n",
    "group_structure = pd.DataFrame(\n",
    "    [(v, a) for v in pred_pss_values for a in pred_accuracies],\n",
    "    columns=['Pred_PSS_Value', 'Pred_Accuracy']\n",
    ")\n",
    "\n",
    "# Group by and calculate means\n",
    "grouped_rmse_mean = Pred_PSS_Accuracy.groupby([\"Pred_PSS_Value\", \"Pred_Accuracy\"])[\"RMSE\"].mean().reset_index()\n",
    "file_mean = group_structure.merge(grouped_rmse_mean, on=['Pred_PSS_Value', 'Pred_Accuracy'], how='left')\n",
    "\n",
    "# Pivot to create mean_df\n",
    "mean_df = file_mean.pivot(index=\"Pred_PSS_Value\", columns=\"Pred_Accuracy\", values=\"RMSE\")\n",
    "\n",
    "# Convert mean_df to a slice of the 3D matrix\n",
    "slice_matrix = np.full((len(pred_pss_values), len(pred_accuracies)), np.nan)\n",
    "for pss_val, row in mean_df.iterrows():\n",
    "    for acc_val, rmse in row.items():\n",
    "        if not np.isnan(rmse):\n",
    "            slice_matrix[pss_index[pss_val], accuracy_index[acc_val]] = rmse\n",
    "\n",
    "# Add the slice to the list\n",
    "all_mean_dfs.append(slice_matrix)\n",
    "# Add list of PSS_Accuracy to mega list\n",
    "final_pred_pss_accuracy = pd.concat([final_pred_pss_accuracy, Pred_PSS_Accuracy], ignore_index=True)\n",
    "\n",
    "final_pred_pss_accuracy.to_csv(\"./10000_simulated_participants_100_400_pred_pss_accuracy.tsv\", sep = '\\t', index=False)  \n",
    "np.save('./10000_simulated_participants_100_400_all_mean_rmse_plot.npy', all_mean_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063a6b7f-1cff-4a46-86b3-ba9c9269034d",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "# If all files have been generated run from here on:\n",
    "<a id=\"skip-here\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2486a1d5-3eb8-43ba-abcc-2be83dd5eb30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#REFERENCE FILES:\n",
    "ref_diff_df = pd.read_csv(\"/PATH/Reference_diff_df_100_400.csv\")  \n",
    "\n",
    "#NULL FILES\n",
    "null_pred_pss_accuracy = pd.read_csv(\"/PATH//10000_null_simulations_100_400_pred_pss_accuracy.csv\")  \n",
    "null_all_mean_dfs = np.load(\"/PATH//10000_null_simulations_100_400_all_mean_rmse_plot.npy\")\n",
    "null_diff_df = pd.read_csv(\"/PATH//Null_diff_df_100_400.csv\")  \n",
    "\n",
    "## SIMULATED PARTICIPANT FILES:\n",
    "sim_participant_pred_pss_accuracy = pd.read_csv('/PATH/10000_simulated_participants_100_400_pred_pss_accuracy_FULLRANGE.tsv', sep='\\t')\n",
    "sim_participant_all_mean_df = np.load(\"/PATH//10000_simulated_participants_100_400_all_mean_rmse_plot_FULLRANGE.npy\")\n",
    "sim_participant_diff_df = pd.read_csv(\"/PATH/10000_simulated_participants_diff_df_100_400.csv\")  \n",
    "\n",
    "# Define fixed ranges for the structure\n",
    "pred_pss_values = np.arange(100, 401, 50)  # Pred_PSS_Value: 0 to 400, increments of 50\n",
    "pred_accuracies = np.arange(0, 1.1, 0.1).round(1)  # Pred_Accuracy: 0.1 to 1.0, increments of 0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8d519a-4de0-45c2-8368-61f7dd9c26df",
   "metadata": {},
   "source": [
    "# ✅❎ Compare Predicted to True: Simulated sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fef6fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out excluded participants\n",
    "True_and_Pred = sim_participant_pred_pss_accuracy[~sim_participant_pred_pss_accuracy['Participant_ID'].isin(set(exclude_ids_parallel) | set(exclude_ids_random))]\n",
    "\n",
    "# Define figure size in cm\n",
    "fig_width_cm = 8\n",
    "fig_height_cm = 6\n",
    "fig_size_in = (fig_width_cm / 2.54, fig_height_cm / 2.54)\n",
    "\n",
    "# Define full range of accuracy values and proportions\n",
    "full_accuracy_vals = np.arange(0, 101, 10)\n",
    "full_accuracy_props = full_accuracy_vals / 100\n",
    "\n",
    "# --- True Accuracy vs PSS Value ---\n",
    "grouped_true = True_and_Pred.groupby([\"True_PSS_Value\", \"True_Accuracy\"]).size().reset_index(name=\"Frequency\")\n",
    "heatmap_data_true = grouped_true.pivot(index=\"True_PSS_Value\", columns=\"True_Accuracy\", values=\"Frequency\").fillna(0)\n",
    "heatmap_data_true = heatmap_data_true.reindex(columns=full_accuracy_props, fill_value=0).iloc[::-1]\n",
    "\n",
    "plt.figure(figsize=fig_size_in, dpi=300)\n",
    "ax1 = sns.heatmap(\n",
    "    heatmap_data_true,\n",
    "    cmap=sim_participant_cmap,\n",
    "    annot=True,\n",
    "    fmt=\".0f\",\n",
    "    vmin=0,\n",
    "    vmax=400,\n",
    "    annot_kws={\"size\": 5},\n",
    "    cbar_kws={\"label\": \"Frequency of sample\"}\n",
    ")\n",
    "ax1.set_xticks(np.arange(len(full_accuracy_vals)) + 0.5)\n",
    "ax1.set_xticklabels(full_accuracy_vals, fontsize=7)\n",
    "ax1.set_yticklabels(ax1.get_yticklabels(), fontsize=7)\n",
    "ax1.set_xlabel(\"True Accuracy (%)\", fontsize=7)\n",
    "ax1.set_ylabel(\"True PSS Value (ms)\", fontsize=7)\n",
    "ax1.collections[0].colorbar.ax.tick_params(labelsize=7)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"10000_simulated_participants_100_400_true_pss_accuracy.png\")\n",
    "plt.show()\n",
    "\n",
    "# --- Predicted Accuracy vs Predicted PSS Value ---\n",
    "grouped_pred = True_and_Pred.groupby([\"Pred_PSS_Value\", \"Pred_Accuracy\"]).size().reset_index(name=\"Frequency\")\n",
    "heatmap_data_pred = grouped_pred.pivot(index=\"Pred_PSS_Value\", columns=\"Pred_Accuracy\", values=\"Frequency\").fillna(0)\n",
    "heatmap_data_pred = heatmap_data_pred.reindex(columns=full_accuracy_props, fill_value=0).iloc[::-1]\n",
    "\n",
    "plt.figure(figsize=fig_size_in, dpi=300)\n",
    "ax2 = sns.heatmap(\n",
    "    heatmap_data_pred,\n",
    "    cmap=sim_participant_cmap,\n",
    "    annot=True,\n",
    "    fmt=\".0f\",\n",
    "    vmin=0,\n",
    "    vmax=400,\n",
    "    annot_kws={\"size\": 5},\n",
    "    cbar_kws={\"label\": \"Frequency of sample\"}\n",
    ")\n",
    "ax2.set_xticks(np.arange(len(full_accuracy_vals)) + 0.5)\n",
    "ax2.set_xticklabels(full_accuracy_vals, fontsize=7)\n",
    "ax2.set_yticklabels(ax2.get_yticklabels(), fontsize=7)\n",
    "ax2.set_xlabel(\"Predicted Accuracy (%)\", fontsize=7)\n",
    "ax2.set_ylabel(\"Predicted PSS Value (ms)\", fontsize=7)\n",
    "ax2.collections[0].colorbar.ax.tick_params(labelsize=7)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"10000_simulated_participants_100_400_pred_pss_accuracy.png\")\n",
    "plt.show()\n",
    "\n",
    "# --- Mean RMSE heatmap ---\n",
    "sim_participant_all_mean_df_plot = np.array(sim_participant_all_mean_df)\n",
    "sim_participants_mean_across_slices = np.nanmean(sim_participant_all_mean_df_plot, axis=0)\n",
    "sim_participants_mean_df_result = pd.DataFrame(\n",
    "    sim_participants_mean_across_slices,\n",
    "    index=pred_pss_values,\n",
    "    columns=pred_accuracies\n",
    ")\n",
    "sim_participants_mean_df_result = sim_participants_mean_df_result.reindex(columns=full_accuracy_props, fill_value=0).iloc[::-1]\n",
    "\n",
    "plt.figure(figsize=fig_size_in, dpi=300)\n",
    "ax3 = sns.heatmap(\n",
    "    sim_participants_mean_df_result,\n",
    "    annot=True,\n",
    "    fmt=\".1f\",\n",
    "    cmap=sim_participant_cmap,\n",
    "    vmin=0,\n",
    "    annot_kws={\"size\": 5},\n",
    "    cbar_kws={'label': 'Mean RMSE'}\n",
    ")\n",
    "ax3.set_xticks(np.arange(len(full_accuracy_vals)) + 0.5)\n",
    "ax3.set_xticklabels(full_accuracy_vals, fontsize=7)\n",
    "ax3.set_yticklabels(ax3.get_yticklabels(), fontsize=7)\n",
    "ax3.set_xlabel(\"Predicted Accuracy (%)\", fontsize=7)\n",
    "ax3.set_ylabel(\"Predicted PSS Value (ms)\", fontsize=7)\n",
    "ax3.collections[0].colorbar.ax.tick_params(labelsize=7)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"10000_simulated_participants_100_400_all_mean_rmse_plot.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db468ed-f6fe-457f-bf30-3595d450b4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract accuracy values\n",
    "true_acc_values = True_and_Pred[\"True_Accuracy\"]\n",
    "pred_acc_values = True_and_Pred[\"Pred_Accuracy\"]\n",
    "fig_width_cm = 6\n",
    "fig_height_cm = 6  # adjust as needed\n",
    "fig_size_in = (fig_width_cm / 2.54, fig_height_cm / 2.54)  # convert cm to inches\n",
    "\n",
    "true_acc_values = True_and_Pred[\"True_Accuracy\"] * 100\n",
    "pred_acc_values = True_and_Pred[\"Pred_Accuracy\"] * 100\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=fig_size_in, dpi= 300)\n",
    "sns.histplot(true_acc_values, bins=21, color=\"#ecd1b7\", label=\"True Accuracy\", kde=False, alpha=0.7)\n",
    "sns.histplot(pred_acc_values, bins=21, color=\"#e17a4b\", label=\"Predicted Accuracy\", kde=False, alpha=0.4)\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Accuracy Level (%)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of True vs Predicted Accuracy\")\n",
    "#plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d0ef59-e212-4faf-b81e-df6c8fb4c866",
   "metadata": {},
   "source": [
    "## ✅❎ 3 Thresholds of Correct \n",
    "\n",
    "🟩100%\n",
    "\n",
    "🟧+/- 50ms 10%\n",
    "\n",
    "🟥+/- 100ms 20%\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5f5af4",
   "metadata": {},
   "source": [
    "\n",
    "___________________________\n",
    "🟩100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3df7dcb-da10-47f2-a46a-18fbe24f4879",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#True_and_Pred = sim_participant_pred_pss_accuracy\n",
    "\n",
    "## PSS  \n",
    "True_and_Pred['Diff_true_pred_PSS'] = True_and_Pred['True_PSS_Value'] - True_and_Pred['Pred_PSS_Value']\n",
    "zero_diff_df_pss = True_and_Pred[True_and_Pred['Diff_true_pred_PSS'] == 0]\n",
    "n_pss = zero_diff_df_pss['Participant_ID'].nunique()\n",
    "total_participants = True_and_Pred['Participant_ID'].nunique()\n",
    "perc_pss = round((n_pss / total_participants) * 100, 2)\n",
    "print(f\"{n_pss} participants ({perc_pss}%) had their PSS score predicted with perfect accuracy\")\n",
    "print(f\"\\n{n_pss} participants ({perc_pss}%) had PSS correctly identified\")\n",
    "print(f\"Mean diff between true PSS and predicted PSS: {True_and_Pred['Diff_true_pred_PSS'].mean()} +/- {True_and_Pred['Diff_true_pred_PSS'].std()}\")\n",
    "\n",
    "## ACCURACY:\n",
    "True_and_Pred['Diff_true_pred'] = True_and_Pred['True_Accuracy'] -  True_and_Pred['Pred_Accuracy']\n",
    "zero_diff_df_accuracy = True_and_Pred[True_and_Pred['Diff_true_pred'] == 0]\n",
    "n_accuracy = zero_diff_df_accuracy['Participant_ID'].nunique()\n",
    "perc_accuracy = round((n_accuracy / total_participants) * 100, 2)\n",
    "print(f\"{n_accuracy} participants ({perc_accuracy}%) had accuracy correctly identified\")\n",
    "print(f\"Mean diff between true Accuracy and predicted Accuracy: {True_and_Pred['Diff_true_pred'].mean()} +/- {True_and_Pred['Diff_true_pred'].std()} \\n\")\n",
    "\n",
    "def calculate_accuracy_100(row):\n",
    "    if (row[\"Pred_PSS_Value\"] == row[\"True_PSS_Value\"]) and (row[\"Pred_Accuracy\"] == row[\"True_Accuracy\"]):\n",
    "        return 1  # Fully accurate\n",
    "    else:\n",
    "        return 0  # Not accurate\n",
    "\n",
    "True_and_Pred[\"Correctly_Identified\"] = True_and_Pred.apply(calculate_accuracy_100, axis=1)\n",
    "\n",
    "## PSS and ACCURACY:\n",
    "correct = True_and_Pred[\"Correctly_Identified\"].sum()\n",
    "correct_perc = round((correct / total_participants) * 100, 2)\n",
    "print(f\"{correct} participants ({correct_perc}%) had both PSS and Accuracy correctly identified\")\n",
    "\n",
    "## Transform for plotting\n",
    "# Transform for plotting\n",
    "grouped = True_and_Pred.groupby([\"Pred_Accuracy\", \"Pred_PSS_Value\"]).agg(\n",
    "    Correct_Percentage=(\"Correctly_Identified\", \"mean\")\n",
    ").reset_index()\n",
    "\n",
    "grouped[\"Correct_Percentage\"] *= 100\n",
    "heatmap_data = grouped.pivot(index=\"Pred_PSS_Value\", columns=\"Pred_Accuracy\", values=\"Correct_Percentage\")\n",
    "heatmap_data = heatmap_data.iloc[::-1]\n",
    "\n",
    "fig_width_cm = 8\n",
    "fig_height_cm = 6\n",
    "fig_size_in = (fig_width_cm / 2.54, fig_height_cm / 2.54)\n",
    "\n",
    "plt.figure(figsize=fig_size_in, dpi=300)\n",
    "ax = sns.heatmap(\n",
    "    heatmap_data, \n",
    "    cmap=sim_participant_cmap, \n",
    "    vmin=0,\n",
    "    vmax=100,\n",
    "    annot=True,\n",
    "    fmt=\".1f\",\n",
    "    annot_kws={\"size\": 5},\n",
    "    cbar_kws={\"label\": \"Percentage Correctly Identified\"}\n",
    ")\n",
    "\n",
    "# Define full range of accuracy values and proportions for ticks\n",
    "full_accuracy_vals = np.arange(0, 101, 10)\n",
    "full_accuracy_props = full_accuracy_vals / 100\n",
    "\n",
    "ax.set_xticks(np.arange(len(full_accuracy_vals)) + 0.5)\n",
    "ax.set_xticklabels(full_accuracy_vals, fontsize=7)\n",
    "ax.set_yticklabels(ax.get_yticklabels(), fontsize=7)\n",
    "ax.set_xlabel(\"Predicted Accuracy (%)\", fontsize=7)\n",
    "ax.set_ylabel(\"Predicted PSS Value (ms)\", fontsize=7)\n",
    "ax.collections[0].colorbar.ax.tick_params(labelsize=7)\n",
    "plt.title(\"Percentage Correctly Identified 100%\", fontsize=7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef05277a-5178-40ae-aacc-4db6cb69ad9e",
   "metadata": {},
   "source": [
    "🟧+/- 50ms 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b73c56-bd30-48ab-a821-c5062086ee74",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## PSS\n",
    "# Calculate the absolute difference between true PSS and predicted PSS\n",
    "True_and_Pred['Abs_Diff_true_pred_PSS'] = abs(\n",
    "    True_and_Pred['True_PSS_Value'] - True_and_Pred['Pred_PSS_Value']\n",
    ")\n",
    "within_50_df = True_and_Pred[True_and_Pred['Abs_Diff_true_pred_PSS'] <= 51]\n",
    "participants_within_50 = within_50_df['Participant_ID'].nunique()\n",
    "total_participants = True_and_Pred['Participant_ID'].nunique()\n",
    "percent_within_50 = round((participants_within_50 / total_participants) * 100, 2)\n",
    "print(f\"{participants_within_50} participants ({percent_within_50}%) had Pred_PSS_Value within 50ms of their true PSS value.\")\n",
    "\n",
    "## ACCURACY:\n",
    "# Calculate the absolute difference between true accuracy and predicted accuracy\n",
    "True_and_Pred['Abs_Diff_true_pred_accuracy'] = abs(\n",
    "    True_and_Pred['True_Accuracy'] - True_and_Pred['Pred_Accuracy']\n",
    ")\n",
    "within_0_1_df = True_and_Pred[True_and_Pred['Abs_Diff_true_pred_accuracy'] <= 0.1]\n",
    "participants_within_0_1 = within_0_1_df['Participant_ID'].nunique()\n",
    "percent_within_0_1 = round((participants_within_0_1 / total_participants) * 100, 2)\n",
    "print(f\"{participants_within_0_1} participants ({percent_within_0_1}%) had Pred_Accuracy within 10% of their true Accuracy.\")\n",
    "\n",
    "## How many were 100% correct - Both PSS and ACCURACY:\n",
    "correct = (True_and_Pred[\"Correctly_Identified\"] != 0).sum().sum()\n",
    "correct_perc = round((correct / total_participants) * 100, 2)\n",
    "print(f\"{correct} participants ({correct_perc}%) had both PSS and Accuracy identified within 50ms PSS and 10% accuracy.\")\n",
    "\n",
    "def calculate_accuracy_100_50(row):\n",
    "    if (row[\"Pred_PSS_Value\"] == row[\"True_PSS_Value\"]) and (row[\"Pred_Accuracy\"] == row[\"True_Accuracy\"]):\n",
    "        return 1  # Fully accurate\n",
    "    elif (abs(row[\"Pred_PSS_Value\"] - row[\"True_PSS_Value\"]) <= 51) and (abs(row[\"Pred_Accuracy\"] - row[\"True_Accuracy\"]) <= 0.11):\n",
    "        return 0.5  # Partially accurate\n",
    "    else:\n",
    "        return 0  # Not accurate\n",
    "\n",
    "True_and_Pred[\"Correctly_Identified\"] = True_and_Pred.apply(calculate_accuracy_100_50, axis=1)\n",
    "\n",
    "grouped = True_and_Pred.groupby([\"Pred_Accuracy\", \"Pred_PSS_Value\"]).agg(\n",
    "    Correct_Percentage=(\"Correctly_Identified\", \"mean\")\n",
    ").reset_index()\n",
    "\n",
    "## How many were 100% correct - Both PSS and ACCURACY:\n",
    "correct = (True_and_Pred[\"Correctly_Identified\"] != 0).sum().sum()\n",
    "correct_perc = round((correct / total_participants) * 100, 2)\n",
    "print(f\"{correct} participants ({correct_perc}%) had both PSS and Accuracy identified within 50ms PSS and 10% accuracy.\")\n",
    "\n",
    "display(HTML(True_and_Pred.head().to_html()))\n",
    "print(f\"{correct} participants correctly identified within 50ms PSS and 10% accuracy\")\n",
    "\n",
    "grouped[\"Correct_Percentage\"] *= 100\n",
    "\n",
    "heatmap_data = grouped.pivot(index=\"Pred_PSS_Value\", columns=\"Pred_Accuracy\", values=\"Correct_Percentage\")\n",
    "heatmap_data = heatmap_data.iloc[::-1]\n",
    "\n",
    "fig_width_cm = 8\n",
    "fig_height_cm = 6\n",
    "fig_size_in = (fig_width_cm / 2.54, fig_height_cm / 2.54)\n",
    "\n",
    "plt.figure(figsize=fig_size_in, dpi=300)\n",
    "ax = sns.heatmap(\n",
    "    heatmap_data, \n",
    "    cmap=sim_participant_cmap, \n",
    "    vmin=0,\n",
    "    vmax=100,\n",
    "    annot=True,\n",
    "    fmt=\".1f\",\n",
    "    annot_kws={\"size\": 5},\n",
    "    cbar_kws={\"label\": \"Percentage Correctly Identified\"}\n",
    ")\n",
    "\n",
    "# Define full range of accuracy values and proportions for ticks\n",
    "full_accuracy_vals = np.arange(0, 101, 10)\n",
    "full_accuracy_props = full_accuracy_vals / 100\n",
    "\n",
    "ax.set_xticks(np.arange(len(full_accuracy_vals)) + 0.5)\n",
    "ax.set_xticklabels(full_accuracy_vals, fontsize=7)\n",
    "ax.set_yticklabels(ax.get_yticklabels(), fontsize=7)\n",
    "ax.set_xlabel(\"Predicted Accuracy (%)\", fontsize=7)\n",
    "ax.set_ylabel(\"Predicted PSS Value (ms)\", fontsize=7)\n",
    "ax.collections[0].colorbar.ax.tick_params(labelsize=7)\n",
    "\n",
    "plt.title(\"within 50ms PSS and 10% Accuracy\", fontsize=7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deebbeb-ee32-4897-97c1-d71faa774e5a",
   "metadata": {},
   "source": [
    "🟥+/- 100ms 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd58ec35-3633-4506-9af2-a71a25001aee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## How many were 100% +/- 100ms PSS and 20% correct:\n",
    "\n",
    "## PSS\n",
    "within_100_df = True_and_Pred[True_and_Pred['Abs_Diff_true_pred_PSS'] <= 101]\n",
    "participants_within_100 = within_100_df['Participant_ID'].nunique()\n",
    "percent_within_100 = round((participants_within_100 / total_participants) * 100, 2)\n",
    "print(f\"{participants_within_100} participants ({percent_within_100}%) had Pred_PSS_Value within 100ms of their true PSS value.\")\n",
    "\n",
    "## ACCURACY\n",
    "within_0_2_df = True_and_Pred[True_and_Pred['Abs_Diff_true_pred_accuracy'] <= 0.2]\n",
    "participants_within_0_2 = within_0_2_df['Participant_ID'].nunique()\n",
    "percent_within_0_2 = round((participants_within_0_2 / total_participants) * 100, 2)\n",
    "print(f\"{participants_within_0_2} participants ({percent_within_0_2}%) had Pred_Accuracy within 20% of their true Accuracy.\")\n",
    "\n",
    "def calculate_accuracy_100_50_25(row):\n",
    "    if (row[\"Pred_PSS_Value\"] == row[\"True_PSS_Value\"]) and (row[\"Pred_Accuracy\"] == row[\"True_Accuracy\"]):\n",
    "        return 1  # Fully accurate\n",
    "    elif (abs(row[\"Pred_PSS_Value\"] - row[\"True_PSS_Value\"]) <= 51) and (abs(row[\"Pred_Accuracy\"] - row[\"True_Accuracy\"]) <= 0.11):\n",
    "        return 0.5  # Partially accurate\n",
    "    elif (abs(row[\"Pred_PSS_Value\"] - row[\"True_PSS_Value\"]) <= 101) and (abs(row[\"Pred_Accuracy\"] - row[\"True_Accuracy\"]) <= 0.21):\n",
    "        return 0.25  # Somewhat accurate\n",
    "    else:\n",
    "        return 0  # Not accurate\n",
    "\n",
    "# Apply classification\n",
    "True_and_Pred[\"Correctly_Identified\"] = True_and_Pred.apply(calculate_accuracy_100_50_25, axis=1)\n",
    "display(HTML(True_and_Pred.head().to_html()))\n",
    "\n",
    "correct = (True_and_Pred[\"Correctly_Identified\"] != 0).sum().sum()\n",
    "correct_perc = round((correct / True_and_Pred['Participant_ID'].nunique()) * 100, 2)\n",
    "print(f\"{correct} participants ({correct_perc}%) had both PSS and Accuracy correctly identified within 100ms PSS and 20% Accuracy.\")\n",
    "\n",
    "# Grouped accuracy for heatmap\n",
    "grouped = True_and_Pred.groupby([\"Pred_Accuracy\", \"Pred_PSS_Value\"]).agg(\n",
    "    Correct_Percentage=(\"Correctly_Identified\", \"mean\")\n",
    ").reset_index()\n",
    "\n",
    "grouped[\"Correct_Percentage\"] *= 100\n",
    "\n",
    "heatmap_data = grouped.pivot(index=\"Pred_PSS_Value\", columns=\"Pred_Accuracy\", values=\"Correct_Percentage\")\n",
    "heatmap_data = heatmap_data.iloc[::-1]\n",
    "\n",
    "fig_width_cm = 8\n",
    "fig_height_cm = 6\n",
    "fig_size_in = (fig_width_cm / 2.54, fig_height_cm / 2.54)\n",
    "\n",
    "plt.figure(figsize=fig_size_in, dpi=300)\n",
    "ax = sns.heatmap(\n",
    "    heatmap_data, \n",
    "    cmap=sim_participant_cmap, \n",
    "    vmin=0,\n",
    "    vmax=100,\n",
    "    annot=True,\n",
    "    fmt=\".1f\",\n",
    "    annot_kws={\"size\": 5},\n",
    "    cbar_kws={\"label\": \"Percentage Correctly Identified\"}\n",
    ")\n",
    "\n",
    "full_accuracy_vals = np.arange(0, 101, 10)\n",
    "ax.set_xticks(np.arange(len(full_accuracy_vals)) + 0.5)\n",
    "ax.set_xticklabels(full_accuracy_vals, fontsize=7)\n",
    "ax.set_yticklabels(ax.get_yticklabels(), fontsize=7)\n",
    "ax.set_xlabel(\"Predicted Accuracy (%)\", fontsize=7)\n",
    "ax.set_ylabel(\"Predicted PSS Value (ms)\", fontsize=7)\n",
    "ax.collections[0].colorbar.ax.tick_params(labelsize=7)\n",
    "\n",
    "plt.title(\"within 100ms PSS and 20% Accuracy\", fontsize=7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bbbef0-aa23-41aa-b3a5-bdb5d4b0fc96",
   "metadata": {},
   "source": [
    "## SIM PARTICIPANTS: Real vs Predicted PSS and of Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2003c499-8cb8-4fbe-ac01-d3868f9a09cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "# Plot 1: Predicted vs Real PSS\n",
    "plt.subplot(2, 2, 1)\n",
    "\n",
    "# Group by the PSS values and count the occurrences\n",
    "pss_counts = True_and_Pred.groupby(['True_PSS_Value', 'Pred_PSS_Value']).size().reset_index(name='Count')\n",
    "merged_data_with_pss_counts = pd.merge(True_and_Pred, pss_counts, on=['True_PSS_Value', 'Pred_PSS_Value'], how='left')\n",
    "\n",
    "# Calculate the number of unique participants\n",
    "unique_participants = True_and_Pred['Participant_ID'].nunique()\n",
    "merged_data_with_pss_counts['Percent_of_sample'] = (merged_data_with_pss_counts['Count'] / unique_participants) * 100\n",
    "\n",
    "norm_pss = plt.Normalize(vmin=merged_data_with_pss_counts['Percent_of_sample'].min(), vmax=merged_data_with_pss_counts['Percent_of_sample'].max())\n",
    "\n",
    "# Scatter plot with color mapping based on the count of participants\n",
    "scatter_pss = plt.scatter(\n",
    "    merged_data_with_pss_counts['True_PSS_Value'], \n",
    "    merged_data_with_pss_counts['Pred_PSS_Value'], \n",
    "    c=merged_data_with_pss_counts['Percent_of_sample'], \n",
    "    cmap='Reds', alpha=0.6, s=100, norm=norm_pss\n",
    ")\n",
    "\n",
    "plt.plot([0, 600], [0, 600], 'r--', alpha = 0.3)\n",
    "plt.title('Predicted PSS vs Real PSS')\n",
    "plt.xlabel('Real PSS values')\n",
    "plt.ylabel('Predicted PSS values')\n",
    "plt.colorbar(scatter_pss, label='% of sample')\n",
    "\n",
    "\n",
    "\n",
    "# Plot 2: Real Accuracy vs Predicted Accuracy\n",
    "plt.subplot(2, 2, 2)\n",
    "\n",
    "# Group by Accuracy and count the occurrences\n",
    "accuracy_counts = True_and_Pred.groupby(['True_Accuracy', 'Pred_Accuracy']).size().reset_index(name='Count')\n",
    "merged_data_with_accuracy_counts = pd.merge(True_and_Pred, accuracy_counts, on=['True_Accuracy', 'Pred_Accuracy'], how='left')\n",
    "merged_data_with_accuracy_counts['Percent_of_sample'] = (merged_data_with_accuracy_counts['Count'] / unique_participants) * 100\n",
    "\n",
    "# Normalize the count values for color mapping\n",
    "norm_accuracy = plt.Normalize(vmin=merged_data_with_accuracy_counts['Percent_of_sample'].min(), vmax=merged_data_with_accuracy_counts['Percent_of_sample'].max())\n",
    "\n",
    "# Scatter plot with color mapping based on the count of participants\n",
    "scatter_accuracy = plt.scatter(\n",
    "    merged_data_with_accuracy_counts['True_Accuracy']*100, \n",
    "    merged_data_with_accuracy_counts['Pred_Accuracy']*100, \n",
    "    c=merged_data_with_accuracy_counts['Percent_of_sample'], \n",
    "    cmap='Reds', alpha=0.6, s=100, norm=norm_accuracy\n",
    ")\n",
    "\n",
    "plt.plot([0, 100], [0, 100], 'r--',alpha = 0.3)\n",
    "plt.title('Real Accuracy vs Predicted Accuracy')\n",
    "plt.xlabel('Real Accuracy (%)')\n",
    "plt.ylabel('Predicted Accuracy (%)')\n",
    "plt.colorbar(scatter_accuracy, label='% of sample')\n",
    "\n",
    "\n",
    "\n",
    "#Plot 3: CORRECT PSS: Real Accuracy vs Predicted Accuracy\n",
    "plt.subplot(2, 2, 4)\n",
    "\n",
    "# Initialize a list to store filtered data\n",
    "filtered_data = []\n",
    "for participant_id in True_and_Pred['Participant_ID'].unique():\n",
    "    matching_rows = True_and_Pred[True_and_Pred['Participant_ID'] == participant_id]\n",
    "    \n",
    "    # Check if Pred_PSS_Value matches PSS_value\n",
    "    participant_PSS = matching_rows['True_PSS_Value'].iloc[0]\n",
    "    matching_rows = matching_rows[matching_rows['Pred_PSS_Value'] == participant_PSS]\n",
    "    \n",
    "    if len(matching_rows) == 1:\n",
    "        row = matching_rows.iloc[0]\n",
    "        \n",
    "        # Get predicted accuracy (minimum value among accuracy columns)\n",
    "        pred_accuracy = row['Pred_Accuracy']\n",
    "        real_accuracy = row['True_Accuracy']\n",
    "        \n",
    "        # Store relevant data\n",
    "        filtered_data.append({\n",
    "            'Participant_ID': row['Participant_ID'],\n",
    "            'PSS_value_real': row['True_PSS_Value'],\n",
    "            'Real_Accuracy': real_accuracy,\n",
    "            'Pred_Accuracy': pred_accuracy\n",
    "        })\n",
    "\n",
    "# Convert list to DataFrame\n",
    "filtered_data_PSS = pd.DataFrame(filtered_data)\n",
    "\n",
    "# Count occurrences of each (Real_Accuracy, Pred_Accuracy) combination\n",
    "accuracy_counts = (\n",
    "    filtered_data_PSS.groupby(['Real_Accuracy', 'Pred_Accuracy'])\n",
    "    .size()\n",
    "    .reset_index(name='Count')\n",
    ")\n",
    "\n",
    "# Normalize frequency for color mapping\n",
    "accuracy_counts['Frequency'] = (accuracy_counts['Count'] / len(filtered_data_PSS['Participant_ID'].unique())) * 100\n",
    "norm = plt.Normalize(vmin=accuracy_counts['Frequency'].min(), vmax=accuracy_counts['Frequency'].max())\n",
    "\n",
    "# Create scatter plot\n",
    "\n",
    "scatter = plt.scatter(\n",
    "    accuracy_counts['Real_Accuracy'] * 100, \n",
    "    accuracy_counts['Pred_Accuracy'] * 100, \n",
    "    c=accuracy_counts['Frequency'], \n",
    "    cmap='OrRd', alpha=0.6, s=100, norm=norm\n",
    ")\n",
    "\n",
    "# Add reference line\n",
    "plt.plot([0, 100], [0, 100], 'r--', alpha=0.3)\n",
    "\n",
    "# Labels and title\n",
    "plt.title('Correct PSS: Real Accuracy vs Predicted Accuracy')\n",
    "plt.xlabel('Real Accuracy Level (%)')\n",
    "plt.ylabel('Predicted Accuracy (%)')\n",
    "\n",
    "# Color bar\n",
    "plt.colorbar(scatter, label='% of sample')\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "#Plot 4: CORRECT ACCURACY: Real PSS vs Predicted PSS\n",
    "plt.subplot(2, 2, 3)\n",
    "\n",
    "# Initialize a list to store filtered data\n",
    "filtered_data = []\n",
    "for participant_id in True_and_Pred['Participant_ID'].unique():\n",
    "    matching_rows = True_and_Pred[True_and_Pred['Participant_ID'] == participant_id]\n",
    "    \n",
    "    # Check if Pred_PSS_Value matches PSS_value\n",
    "    participant_Accuracy = matching_rows['True_Accuracy'].iloc[0]\n",
    "    matching_rows = matching_rows[matching_rows['Pred_Accuracy'] == participant_Accuracy]\n",
    "    \n",
    "    if len(matching_rows) == 1:\n",
    "        row = matching_rows.iloc[0]\n",
    "        \n",
    "        # Get predicted accuracy (minimum value among accuracy columns)\n",
    "        pred_PSS = row['Pred_PSS_Value']\n",
    "        real_PSS = row['True_PSS_Value']\n",
    "        \n",
    "        # Store relevant data\n",
    "        filtered_data.append({\n",
    "            'Participant_ID': row['Participant_ID'],\n",
    "            'PSS_value_real': row['True_PSS_Value'],\n",
    "            'Real_PSS_value': pred_PSS,\n",
    "            'Pred_PSS_Value': real_PSS\n",
    "        })\n",
    "\n",
    "# Convert list to DataFrame\n",
    "filtered_data_Accuracy = pd.DataFrame(filtered_data)\n",
    "\n",
    "# Count occurrences of each (Real_Accuracy, Pred_Accuracy) combination\n",
    "PSS_counts = (\n",
    "    filtered_data_Accuracy.groupby(['Real_PSS_value', 'Pred_PSS_Value'])\n",
    "    .size()\n",
    "    .reset_index(name='Count')\n",
    ")\n",
    "\n",
    "# Normalize frequency for color mapping\n",
    "PSS_counts['Frequency'] = (PSS_counts['Count'] / len(filtered_data_Accuracy['Participant_ID'].unique())) * 100\n",
    "norm = plt.Normalize(vmin=PSS_counts['Frequency'].min(), vmax=PSS_counts['Frequency'].max())\n",
    "\n",
    "# Create scatter plot\n",
    "\n",
    "scatter = plt.scatter(\n",
    "    PSS_counts['Pred_PSS_Value'], \n",
    "    PSS_counts['Pred_PSS_Value'], \n",
    "    c=PSS_counts['Frequency'], \n",
    "    cmap='OrRd', alpha=0.6, s=100, norm=norm\n",
    ")\n",
    "\n",
    "# Add reference line\n",
    "plt.plot([0, 600], [0, 600], 'r--', alpha=0.3)\n",
    "\n",
    "# Labels and title\n",
    "plt.title('Correct Accuracy: Real PSS vs Predicted PSS')\n",
    "plt.xlabel('Real PSS')\n",
    "plt.ylabel('Predicted PSS')\n",
    "\n",
    "# Color bar\n",
    "plt.colorbar(scatter, label='% of sample')\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0704062e-169a-43bd-94ff-95c92b023252",
   "metadata": {},
   "source": [
    "## SIM PARTICIPANTS:\n",
    "Get P-value for where they fall in the NULL distrubtion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d2049d-8d2b-485d-9a76-46169a871a46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#REFERENCE FILES:\n",
    "ref_diff_df = pd.read_csv(\"/PATH/Reference_diff_df_100_400.csv\")  \n",
    "\n",
    "#NULL FILES\n",
    "null_pred_pss_accuracy = pd.read_csv(\"/PATH/10000_null_simulations_100_400_pred_pss_accuracy.csv\")  \n",
    "null_all_mean_dfs = np.load(\"/PATH/10000_null_simulations_100_400_all_mean_rmse_plot.npy\")\n",
    "null_diff_df = pd.read_csv(\"/PATH/Null_diff_df_100_400.csv\")  \n",
    "\n",
    "## SIMULATED PARTICIPANT FILES:\n",
    "sim_participant_pred_pss_accuracy = pd.read_csv('/PATH/10000_simulated_participants_100_400_pred_pss_accuracy.tsv', sep='\\t')\n",
    "sim_participant_all_mean_df = np.load(\"/PATH/10000_simulated_participants_100_400_all_mean_rmse_plot.npy\")\n",
    "sim_participant_diff_df = pd.read_csv(\"/PATH/10000_simulated_participants_diff_df_100_400.csv\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163f838c-a90f-4da1-b2e5-3a175605f8fc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm, linregress\n",
    "#If plotting - shows disribution and participant as line\n",
    "plotting = False\n",
    "\n",
    "sim_participants_file = f'/PATH/10000_simulated_participants_100_400.tsv'\n",
    "sim_participants_df = pd.read_csv(sim_participants_file, sep='\\t')\n",
    "\n",
    "sim_participant_pred_pss_accuracy = compute_p_values(sim_participant_pred_pss_accuracy, df_vector_across_slices, plotting=True)\n",
    "#Saves p-values into the Pred_PSS_Accuracy_drop_real file\n",
    "sim_participant_pred_pss_accuracy.to_csv('/PATH/10000_simulated_participants_100_400_pred_pss_accuracy_pvals.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce26185-bcfa-49a1-b2d5-6955a8c96b10",
   "metadata": {},
   "source": [
    "## SIM PARTICIPANTS:\n",
    "Disrbution of P-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471fabe0-3f50-4814-afa0-e740004526e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming p_values is defined\n",
    "p_values = sim_participant_pred_pss_accuracy['p_value']\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(p_values, bins=100, kde=True, color='#e86a36', alpha=0.6)\n",
    "plt.title('Distribution of P-values')\n",
    "plt.xlabel('P-value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "ax_inset = inset_axes(plt.gca(), width=\"60%\", height=\"40%\", loc=\"upper right\")\n",
    "\n",
    "# Plot the zoomed-in region\n",
    "sns.histplot(p_values, bins=100, kde=False, color='#e86a36', alpha=0.6, ax=ax_inset)\n",
    "ax_inset.set_xlim(0, 0.08)\n",
    "ax_inset.set_ylim(0, None)  # Adjust if needed\n",
    "ax_inset.set_xticks([0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07])\n",
    "ax_inset.xlabel('P-value')\n",
    "ax_inset.ylabel('Frequency')\n",
    "ax_inset.set_yticks([]) \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf196f0-b21f-4eee-9898-861f02aee27e",
   "metadata": {},
   "source": [
    "## Mean RMSE across participants, sig vs non sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dd447d-6310-4b80-86ae-b638b54685d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "significant_participants = []\n",
    "non_significant_participants  = []\n",
    "# Separate participants into two groups based on p-value\n",
    "significant_participants = sim_participant_pred_pss_accuracy[sim_participant_pred_pss_accuracy['p_value'] < 0.05]\n",
    "print(len(significant_participants))\n",
    "non_significant_participants = sim_participant_pred_pss_accuracy[sim_participant_pred_pss_accuracy['p_value'] >= 0.05]\n",
    "print(len(non_significant_participants))\n",
    "\n",
    "# Calculate the mean RMSE for each group\n",
    "mean_rmse_significant = significant_participants.groupby(['Pred_PSS_Value', 'Pred_Accuracy'])['RMSE'].mean().unstack()\n",
    "mean_rmse_significant = mean_rmse_significant.iloc[::-1]\n",
    "\n",
    "mean_rmse_non_significant = non_significant_participants.groupby(['Pred_PSS_Value', 'Pred_Accuracy'])['RMSE'].mean().unstack()\n",
    "mean_rmse_non_significant = mean_rmse_non_significant.iloc[::-1]\n",
    "\n",
    "# Plot the heatmap for participants with p < 0.05 (significant)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(mean_rmse_significant, cmap=sim_participant_cmap, annot=True, fmt='.2f', cbar_kws={'label': 'Mean RMSE'}, vmin = 0, vmax = 30)\n",
    "plt.title('Heatmap of Mean RMSE for Participants with p < 0.05')\n",
    "plt.xlabel('Pred Accuracy')\n",
    "plt.ylabel('Pred PSS Value')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot the heatmap for participants with p >= 0.05 (non-significant)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(mean_rmse_non_significant, cmap=sim_participant_cmap, annot=True, fmt='.2f', cbar_kws={'label': 'Mean RMSE'}, vmin = 0, vmax = 30)\n",
    "plt.title('Heatmap of Mean RMSE for Participants with p >= 0.05')\n",
    "plt.xlabel('Pred Accuracy')\n",
    "plt.ylabel('Pred PSS Value')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8fd817-cc4f-4cc9-a1f8-ad79e97c2c6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "significant_participants = updated_participant_data[updated_participant_data['p_value'] < 0.05]\n",
    "non_significant_participants = updated_participant_data[updated_participant_data['p_value'] >= 0.05]\n",
    "\n",
    "# Initialize an empty list to store the result\n",
    "vector_across_slices = []\n",
    "\n",
    "# Loop over each (y, x) position (same logic as in the original code)\n",
    "for y in range(all_mean_dfs_plot.shape[1]):  # 12 rows\n",
    "    row = []\n",
    "    for x in range(all_mean_dfs_plot.shape[2]):  # 11 columns\n",
    "        values_at_pos = all_mean_dfs_plot[:, y, x].tolist()\n",
    "        row.append(values_at_pos)\n",
    "    vector_across_slices.append(row)\n",
    "\n",
    "df_vector_across_slices = pd.DataFrame(vector_across_slices)\n",
    "df_vector_across_slices.index = pred_pss_values  # Assuming `pred_pss_values` is the list of index labels\n",
    "df_vector_across_slices.columns = pred_accuracies  # Assuming `pred_accuracies` is the list of column labels\n",
    "\n",
    "# Set the number of rows and columns for the grid of subplots\n",
    "num_rows = df_vector_across_slices.shape[0]\n",
    "num_cols = df_vector_across_slices.shape[1]\n",
    "\n",
    "# Calculate the min/max values for the x and y axis ranges\n",
    "min_xvalue = 0\n",
    "max_xvalue = math.ceil(np.nanmax([item for sublist in df_vector_across_slices.values for item in sublist]) + 0.05)\n",
    "max_yvalue = 0\n",
    "\n",
    "# Find max frequency for scaling y-axis\n",
    "for cell_row in range(num_rows):\n",
    "    for cell_col in range(num_cols):\n",
    "        cell_values = df_vector_across_slices.iloc[cell_row, cell_col]\n",
    "        hist, bin_edges = np.histogram(cell_values, bins=50, range=(min_xvalue, max_xvalue))\n",
    "        max_yvalue = max(max_yvalue, hist.max())\n",
    "\n",
    "# Create figure and axes for subplots\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(15,10))\n",
    "\n",
    "# Loop through each subplot to create histograms\n",
    "for cell_row in range(num_rows):\n",
    "    for cell_col in range(num_cols):\n",
    "        cell_values = df_vector_across_slices.iloc[cell_row, cell_col]\n",
    "        ax = axes[num_rows - 1 - cell_row, cell_col]  # Flip the row order\n",
    "\n",
    "        # Plot the histogram for the null distribution\n",
    "        sns.histplot(cell_values, bins=50, kde=True, color='#99c3dd', edgecolor='#99c3dd', alpha=0.7, ax=ax, \n",
    "                     binrange=(min_xvalue, max_xvalue))\n",
    "\n",
    "        # Overlay the RMSE values for significant and non-significant participants\n",
    "        significant_rmse_values = significant_participants[\n",
    "            (significant_participants['Pred_PSS_Value'] == pred_pss_values[cell_row]) &\n",
    "            (significant_participants['Pred_Accuracy'] == pred_accuracies[cell_col])\n",
    "        ]['RMSE']\n",
    "        non_significant_rmse_values = non_significant_participants[\n",
    "            (non_significant_participants['Pred_PSS_Value'] == pred_pss_values[cell_row]) &\n",
    "            (non_significant_participants['Pred_Accuracy'] == pred_accuracies[cell_col])\n",
    "        ]['RMSE']\n",
    "\n",
    "        # Plot vertical lines for significant RMSE values in red\n",
    "        for rmse_value in significant_rmse_values:\n",
    "            ax.vlines(rmse_value, 0, max_yvalue, color='#ff6600', alpha=0.1, linewidth=1.5, label='Significant')\n",
    "\n",
    "        # Plot vertical lines for non-significant RMSE values in blue\n",
    "        for rmse_value in non_significant_rmse_values:\n",
    "            ax.vlines(rmse_value, 0, max_yvalue, color='#ff6600', alpha=0.1, linewidth=1.5, linestyles= 'dashed',label='Non-Significant')\n",
    "\n",
    "        # Remove axis labels and ticks for a clean look\n",
    "        ax.set_xticks([]) \n",
    "        ax.set_yticks([]) \n",
    "        ax.set_ylabel('')\n",
    "\n",
    "        # Set axis limits\n",
    "        ax.set_xlim(min_xvalue, max_xvalue)\n",
    "        ax.set_ylim(0, max_yvalue)\n",
    "\n",
    "        # Clean grid appearance\n",
    "        if cell_col == num_cols - 1:\n",
    "            ax.spines['top'].set_visible(True)\n",
    "            ax.spines['right'].set_visible(True)\n",
    "            ax.spines['left'].set_visible(True)\n",
    "            ax.spines['bottom'].set_visible(True)\n",
    "        else:\n",
    "            ax.spines['top'].set_visible(True)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "            ax.spines['left'].set_visible(True)\n",
    "            ax.spines['bottom'].set_visible(True)\n",
    "\n",
    "        if cell_row == 0 and cell_col == 0:\n",
    "            ax.set_xticks(np.linspace(min_xvalue, max_xvalue, num=2))\n",
    "        else:\n",
    "            ax.set_xticks([])\n",
    "\n",
    "        if cell_col == 0 and cell_row == 0:\n",
    "            ax.set_yticks(np.linspace(0, max_yvalue, num=2))\n",
    "\n",
    "# Left Y-axis (Pred_PSS_Value)\n",
    "ax_left = fig.add_axes([0.065, 0.1, 0.01, 0.75])\n",
    "ax_left.set_xticks([])  \n",
    "ax_left.tick_params(axis=\"y\", direction=\"out\", length=12, width=1.2)\n",
    "ax_left.set_yticks(np.arange(num_rows) + 0.5)\n",
    "ax_left.set_yticklabels(pred_pss_values, fontsize=10, ha='right')\n",
    "ax_left.set_ylabel(\"Predicted PSS Value\\nNumber of instances\", fontsize=12, labelpad=20)\n",
    "ax_left.tick_params(left=False, labelleft=True, right=False, labelright=False)\n",
    "ax_left.spines['top'].set_visible(False)\n",
    "ax_left.spines['bottom'].set_visible(False)\n",
    "ax_left.spines['left'].set_visible(False)\n",
    "ax_left.spines['right'].set_visible(False)\n",
    "\n",
    "# Bottom X-axis (Pred_Accuracy)\n",
    "ax_bottom = fig.add_axes([0.16, 0.06, 0.7, 0.01])\n",
    "ax_bottom.set_yticks([])  \n",
    "ax_bottom.set_xticks(np.arange(num_cols))\n",
    "ax_bottom.set_xticklabels(pred_accuracies, rotation=0, fontsize=10, ha='center')\n",
    "ax_bottom.set_xlabel(\"RMSE\\nPredicted Accuracy\", fontsize=12, labelpad=15)\n",
    "ax_bottom.tick_params(axis=\"x\", direction=\"inout\", length=6, width=1.2)\n",
    "ax_bottom.spines['top'].set_visible(False)\n",
    "ax_bottom.spines['bottom'].set_visible(False)\n",
    "ax_bottom.spines['left'].set_visible(False)\n",
    "ax_bottom.spines['right'].set_visible(False)\n",
    "\n",
    "# Adjust layout to fit the grid tightly\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.savefig(\"overlayed_vertical_line_distribution_plots.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec848d63-d8e5-46d5-9cd2-3e16afcae9b2",
   "metadata": {},
   "source": [
    "### Probe the difference in RMSE between the predicted and true values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d080d066-cd85-478e-aee5-60daaaacc4bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "real_vs_pred_rmse = pd.read_csv('/PATH/1000_participant_simulations_100_400_pred_pss_accuracy_withtrueRMSE_pvals.tsv', sep = '\\t')\n",
    "real_vs_pred_rmse['Diff_rmse'] = real_vs_pred_rmse['True_RMSE'] -real_vs_pred_rmse['RMSE']\n",
    "display(HTML(real_vs_pred_rmse.head().to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06d1f83-d101-4390-a98f-a8b53b858776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert Accuracy to categorical explicitly\n",
    "real_vs_pred_rmse['Accuracy'] = real_vs_pred_rmse['Accuracy'].astype(str)  # Convert to string to force categorical behavior\n",
    "\n",
    "# Set plot size\n",
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "# Create a box plot for Diff_rmse\n",
    "#sns.boxplot(y=real_vs_pred_rmse['Diff_rmse'], color='lightgray', width=0.3)\n",
    "\n",
    "# Overlay scatter plot\n",
    "sns.stripplot(y=real_vs_pred_rmse['Diff_rmse'], \n",
    "              x=[0] * len(real_vs_pred_rmse),  # Fix x-axis issue\n",
    "              hue=real_vs_pred_rmse['Accuracy'], \n",
    "              size=real_vs_pred_rmse['PSS_value'] / 25,  # Adjust size\n",
    "              palette='tab10',  # Better color variety\n",
    "              jitter=0.4, \n",
    "              alpha=0.7)\n",
    "\n",
    "# Labels and title\n",
    "plt.ylabel('Difference in RMSE (Diff_rmse)')\n",
    "plt.xlabel('')\n",
    "plt.title('Box Plot of Diff_rmse with Scatter Points')\n",
    "\n",
    "# Adjust legend\n",
    "plt.legend(title='Accuracy', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0268d63-d711-4ac2-b65b-04d0e25bef66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "real_vs_pred_rmse['Diff_rmse'] = real_vs_pred_rmse['True_RMSE'] -real_vs_pred_rmse['RMSE']\n",
    "#print(real_vs_pred_rmse)\n",
    "# Set plot size\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Create a box plot for Diff_rmse\n",
    "sns.boxplot(y=real_vs_pred_rmse['Diff_rmse'], color='lightgray', width=0.3)\n",
    "\n",
    "# Overlay scatter plot\n",
    "sns.stripplot(y=real_vs_pred_rmse['Diff_rmse'], \n",
    "              x=[0] * len(real_vs_pred_rmse),  # Fix x-axis issue\n",
    "              hue=real_vs_pred_rmse['PSS_value'], \n",
    "              size = 15,\n",
    "              palette='tab20',  # Better color variety\n",
    "              jitter=0.4, \n",
    "              alpha=0.7)\n",
    "\n",
    "# Labels and title\n",
    "plt.ylabel('Difference in RMSE (Diff_rmse)')\n",
    "plt.xlabel('')\n",
    "plt.title('Box Plot of Diff_rmse with Scatter Points')\n",
    "\n",
    "# Adjust legend\n",
    "plt.legend(title='PSS value', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd69d6c-b776-4efa-a61a-15c8a6f39c21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ensure Accuracy is categorical (convert to string for proper grouping)\n",
    "\n",
    "# Ensure Accuracy is categorical (convert to string for proper grouping)\n",
    "real_vs_pred_rmse['Accuracy'] = real_vs_pred_rmse['Accuracy'].astype(str)\n",
    "\n",
    "# Set plot size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Identify Accuracy categories that have variance \n",
    "unique_accuracy = real_vs_pred_rmse['Accuracy'].unique()\n",
    "\n",
    "# Create a KDE plot for each Accuracy level, excluding those with no variance\n",
    "for accuracy in unique_accuracy:\n",
    "    subset = real_vs_pred_rmse[real_vs_pred_rmse['Accuracy'] == accuracy]\n",
    "    \n",
    "    # Check for variance\n",
    "    if subset['Diff_rmse'].var() > 0:  # If there is variance, plot it\n",
    "        sns.kdeplot(data=subset, \n",
    "                    x=\"Diff_rmse\", \n",
    "                    label=accuracy, \n",
    "                    fill=False,\n",
    "                    common_norm=False,  # Don't normalize across categories\n",
    "                    palette=\"tab10\",  # Use a distinct palette\n",
    "                    alpha=0.1)  # Transparency for better visibility\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Difference in RMSE (Diff_rmse)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Density Plot of Difference Values per Accuracy\")\n",
    "\n",
    "# Show legend\n",
    "plt.legend(title=\"Accuracy\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e987b4-24d6-4beb-913b-83d13f8cfbe3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ensure Accuracy is categorical (convert to string for proper grouping)\n",
    "\n",
    "# Ensure Accuracy is categorical (convert to string for proper grouping)\n",
    "real_vs_pred_rmse['Accuracy'] = real_vs_pred_rmse['Accuracy'].astype(str)\n",
    "\n",
    "# Set plot size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Identify Accuracy categories that have variance \n",
    "unique_accuracy = real_vs_pred_rmse['PSS_value'].unique()\n",
    "\n",
    "# Create a KDE plot for each Accuracy level, excluding those with no variance\n",
    "for accuracy in unique_accuracy:\n",
    "    subset = real_vs_pred_rmse[real_vs_pred_rmse['PSS_value'] == accuracy]\n",
    "    \n",
    "    # Check for variance\n",
    "    if subset['Diff_rmse'].var() > 0:  # If there is variance, plot it\n",
    "        sns.kdeplot(data=subset, \n",
    "                    x=\"Diff_rmse\", \n",
    "                    label=accuracy, \n",
    "                    fill=False,\n",
    "                    common_norm=False,  # Don't normalize across categories\n",
    "                    palette=\"tab20\",  # Use a distinct palette\n",
    "                    alpha=0.1)  # Transparency for better visibility\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Difference in RMSE (Diff_rmse)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Density Plot of Difference Values per PSS\")\n",
    "\n",
    "# Show legend\n",
    "plt.legend(title=\"PSS value\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc73818-adbe-461d-a476-2719c0c9287b",
   "metadata": {},
   "source": [
    "## Plot simulated participant trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148031ce-ca8f-4a00-a495-ea7d8cbfe251",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "pss_value_list = list(range(50, 601, 50))  # [50, 100, 150, ..., 600]\n",
    "accuracy_list = [round(i * 0.1, 1) for i in range(0, 11)]  # [0.0, 0.1, 0.2, ..., 1.0]\n",
    "n_iterations = 100\n",
    "\n",
    "participants_file = f'/PATH/1000_participant_simulations_100_400.tsv'\n",
    "participants_df = pd.read_csv(participants_file, sep='\\t')\n",
    "participants_df['Trial'] = participants_df['Trial'].astype(int)\n",
    "participants_df['Modified_Staircase_name'] = participants_df['Staircase_name'].str[:-2]\n",
    "\n",
    "# Recode trial numbers\n",
    "participants_df.loc[:, 'Recode_Trial'] = np.where(\n",
    "    participants_df['Staircase_name'].str.contains('400'),\n",
    "    participants_df['Trial'], \n",
    "    participants_df['Trial'] + 15\n",
    ")\n",
    "print(participants_df)\n",
    "\n",
    "# Load simulation data\n",
    "simulation_df = pd.read_csv('/PATH/Reference_simulations.tsv', sep='\\t')\n",
    "\n",
    "# Clean column names (remove tabs, strip spaces)\n",
    "simulation_df.columns = [col.strip().replace('\\t', '') for col in simulation_df.columns]\n",
    "\n",
    "simulation_df['Staircase_name'] = simulation_df['Staircase_name'].astype(str)\n",
    "\n",
    "# Get participant IDs\n",
    "participant_ids = participants_df['Participant_ID'].unique().tolist()\n",
    "\n",
    "# Loop over each participant ID\n",
    "for participant_id in participant_ids[639:640]:\n",
    "    participant_id = participant_id  # Extract the numeric part (e.g., '005')\n",
    "    print(participant_id)\n",
    "    # Read the participant's data file\n",
    "    participants_df.columns = [col.strip().replace('\\t', '') for col in participants_df.columns]\n",
    "\n",
    "    participants_df = participants_df[participants_df['Staircase_name'] != 'Training']\n",
    "    participants_df = participants_df[participants_df['Staircase_name'] != 'Post_task_question']\n",
    "    participants_df['Modified_Staircase_name'] = participants_df['Staircase_name'].str[:-2]\n",
    "    participants_df['Trial'] = participants_df['Trial'].astype(int)\n",
    "    \n",
    "\n",
    "    plot_simulations_with_participant_data(simulation_df, participants_df, participant_id, pss_value_list, accuracy_list, n_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0553bdf5-8734-470e-a22c-16aab0e93bbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "# Assuming p_values is defined\n",
    "p_values = updated_participant_data['p_value']\n",
    "\n",
    "# Create the main histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(p_values, bins=100, kde=True, color='#4C72B0', alpha=0.6)\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.title('Distribution of P-values')\n",
    "plt.xlabel('P-value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Create inset axes\n",
    "ax_inset = inset_axes(plt.gca(), width=\"60%\", height=\"40%\", loc=\"center\")\n",
    "\n",
    "# Plot the zoomed-in region\n",
    "sns.histplot(p_values, bins=100, kde=False, color='#4C72B0', alpha=0.6, ax=ax_inset)\n",
    "ax_inset.set_xlim(0, 0.08)\n",
    "ax_inset.set_ylim(0, None) \n",
    "ax_inset.set_xticks([0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07])\n",
    "#ax_inset.xlabel('P-value')\n",
    "#ax_inset.ylabel('Frequency')\n",
    "\n",
    "ax_inset.set_yticks([])  \n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13493a69-5d29-4baa-9703-26a525724ba4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get probability distribution for HDT: 40 x 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37314e50-0985-449b-9c7e-70c86f735537",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "def simulate_trials(n_simulations=10000, n_trials=40, p_correct=0.5):\n",
    "    \"\"\"Simulates random guessing over multiple trials.\"\"\"\n",
    "    results = np.random.binomial(n_trials, p_correct, n_simulations)\n",
    "    return results\n",
    "\n",
    "def calculate_probabilities(sim_results, percentages, n_trials=40, p_correct=0.5):\n",
    "    \"\"\"Calculates the two-tailed probability of achieving a given percentage or more extreme.\"\"\"\n",
    "    # The mean and standard deviation for the binomial distribution (normal approximation)\n",
    "    mean = n_trials * p_correct\n",
    "    std_dev = np.sqrt(n_trials * p_correct * (1 - p_correct))\n",
    "    \n",
    "    # Convert percentages to the number of correct answers\n",
    "    thresholds = [int(p * n_trials) for p in percentages]\n",
    "    \n",
    "    probabilities = []\n",
    "    for threshold in thresholds:\n",
    "        # Calculate z-scores for the lower and upper tails\n",
    "        z_lower = (threshold - mean) / std_dev\n",
    "        z_upper = (n_trials - threshold - mean) / std_dev\n",
    "        \n",
    "        # Find the one-tailed p-value for each tail using the normal distribution\n",
    "        p_lower = norm.cdf(z_lower)\n",
    "        p_upper = norm.cdf(z_upper)\n",
    "        \n",
    "        # Two-tailed p-value: sum the two one-tailed p-values, considering symmetry\n",
    "        p_value = 2 * min(p_lower, p_upper)\n",
    "        \n",
    "        # Append p-value rounded to 4 decimal places\n",
    "        probabilities.append(round(p_value, 4))\n",
    "    \n",
    "    # Prepare the result as a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Percentage': [f\"{int(p * 100)}%\" for p in percentages],\n",
    "        'Two-Tailed P-Value': probabilities\n",
    "    })\n",
    "    \n",
    "    return df, thresholds\n",
    "\n",
    "# Run the simulation\n",
    "sim_results = simulate_trials()\n",
    "\n",
    "# Example: Get probabilities for several percentages\n",
    "#percentages_to_check = [i / 100 for i in range(, 40)]\n",
    "percentages_to_check = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]  # 10%, 20%, ..., 90%\n",
    "df_probabilities, thresholds = calculate_probabilities(sim_results, percentages_to_check)\n",
    "\n",
    "# Display the results as a DataFrame\n",
    "print(df_probabilities)\n",
    "\n",
    "# Plot density plot of simulation results\n",
    "sns.kdeplot(sim_results, fill=True)\n",
    "plt.xlabel(\"Number of Correct Answers\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Density Plot of Simulation Results\")\n",
    "\n",
    "# Add vertical red lines for each percentage threshold\n",
    "for threshold in thresholds:\n",
    "    plt.axvline(threshold, color='red', linestyle='--')\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f2bb46-f7e0-410c-a04c-c698eeb12e61",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Frequency of button presses for HDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be45efa3-2515-4b20-99d1-474a6f5cbf4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Simulation parameters\n",
    "num_participants = 10000\n",
    "num_presses = 40\n",
    "\n",
    "# Simulate random button presses (0 for B1, 1 for B2)\n",
    "button_presses = np.random.choice([0, 1], size=(num_participants, num_presses))\n",
    "\n",
    "# Count occurrences of B1 (0) and B2 (1) per participant\n",
    "b1_counts = np.sum(button_presses == 0, axis=1)\n",
    "b2_counts = np.sum(button_presses == 1, axis=1)\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(b1_counts, bins=range(0, num_presses+2), alpha=0.6, label='B1', color='blue', edgecolor='black')\n",
    "plt.hist(b2_counts, bins=range(0, num_presses+2), alpha=0.6, label='B2', color='red', edgecolor='black')\n",
    "plt.xlabel(\"Number of presses\")\n",
    "plt.ylabel(\"Frequency of participants\")\n",
    "plt.title(\"Histogram of Button Presses per Participant\")\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "## 14 (lower) and 26 (upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332b3de8",
   "metadata": {},
   "source": [
    "# I think I can delete this... but just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fb973d-3c41-4fa6-b42f-344243bfd4ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(12, 12))  # 3 rows, 2 columns\n",
    "axes = axes.flatten()\n",
    "numeric_columns = pivoted_df_with_null.select_dtypes(include=['number']).columns\n",
    "num_plots = min(len(numeric_columns), len(axes))\n",
    "for i in range(num_plots):\n",
    "    col = numeric_columns[i]\n",
    "    ax = axes[i]  # Get the corresponding subplot\n",
    "    sns.kdeplot(pivoted_df_with_null[col], ax=ax, fill=True, color='steelblue', alpha=0.6)\n",
    "    ax.set_title(f'KDE of {col}')\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_xlim(0,30)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Filter the DataFrame for '100' responses\n",
    "pivoted_100_df = pivoted_df_with_null.filter(like='100', axis=1)\n",
    "\n",
    "custom_colors = [ '#e49971', '#ecd1b7','#e17a4b']\n",
    "custom_colors = [ '#87afe6', '#b1d8ec','#6991e1']\n",
    "\n",
    "# Plot for all '100' responses\n",
    "pivoted_100_df.plot(kind='bar', stacked=True, color = custom_colors, figsize=(20, 6))\n",
    "plt.xlabel(\"Participant\")\n",
    "plt.ylabel(\"Sum of Responses\")\n",
    "plt.title(\"Summed '100' Response Percentages by Participant\")\n",
    "plt.legend(title=\"Response Type\")\n",
    "plt.show()\n",
    "\n",
    "# Filter the DataFrame for '400' responses\n",
    "pivoted_400_df = pivoted_df_with_null.filter(like='400', axis=1)\n",
    "\n",
    "# Plot for all '400' responses\n",
    "pivoted_400_df.plot(kind='bar', stacked=True, color = custom_colors, figsize=(20, 6))\n",
    "plt.xlabel(\"Participant\")\n",
    "plt.ylabel(\"Sum of Responses\")\n",
    "plt.title(\"Summed '400' Response Percentages by Participant\")\n",
    "plt.legend(title=\"Response Type\")\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
